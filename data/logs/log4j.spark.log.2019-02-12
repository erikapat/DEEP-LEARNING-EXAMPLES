19/02/12 18:07:24 INFO SparkContext: Running Spark version 2.1.0
19/02/12 18:07:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/02/12 18:07:25 INFO SecurityManager: Changing view acls to: erikapat
19/02/12 18:07:25 INFO SecurityManager: Changing modify acls to: erikapat
19/02/12 18:07:25 INFO SecurityManager: Changing view acls groups to: 
19/02/12 18:07:25 INFO SecurityManager: Changing modify acls groups to: 
19/02/12 18:07:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(erikapat); groups with view permissions: Set(); users  with modify permissions: Set(erikapat); groups with modify permissions: Set()
19/02/12 18:07:25 INFO Utils: Successfully started service 'sparkDriver' on port 34075.
19/02/12 18:07:25 INFO SparkEnv: Registering MapOutputTracker
19/02/12 18:07:25 INFO SparkEnv: Registering BlockManagerMaster
19/02/12 18:07:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/02/12 18:07:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/02/12 18:07:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-14faf80d-1d52-4c73-b473-21a3b6b79d97
19/02/12 18:07:25 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/02/12 18:07:25 INFO SparkEnv: Registering OutputCommitCoordinator
19/02/12 18:07:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/02/12 18:07:26 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
19/02/12 18:07:26 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
19/02/12 18:07:26 INFO Utils: Successfully started service 'SparkUI' on port 4043.
19/02/12 18:07:26 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4043
19/02/12 18:07:26 INFO SparkContext: Added JAR file:/home/erikapat/anaconda3/lib/R/library/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:34075/jars/sparklyr-2.1-2.11.jar with timestamp 1549991246524
19/02/12 18:07:26 INFO Executor: Starting executor ID driver on host localhost
19/02/12 18:07:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45409.
19/02/12 18:07:26 INFO NettyBlockTransferService: Server created on 127.0.0.1:45409
19/02/12 18:07:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/02/12 18:07:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 45409, None)
19/02/12 18:07:26 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:45409 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 45409, None)
19/02/12 18:07:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 45409, None)
19/02/12 18:07:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 45409, None)
19/02/12 18:08:53 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
19/02/12 18:08:53 INFO SharedState: Warehouse path is 'file:/home/erikapat/Dropbox/conento/conento_prueba/PRUEBA%20DATA%20ARQUITECT/Churn.ipynb/spark-warehouse'.
19/02/12 18:08:54 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/02/12 18:08:56 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/02/12 18:08:56 INFO ObjectStore: ObjectStore, initialize called
19/02/12 18:08:57 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/02/12 18:08:57 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/02/12 18:09:02 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/02/12 18:09:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/02/12 18:09:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/02/12 18:09:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/02/12 18:09:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/02/12 18:09:07 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/02/12 18:09:07 INFO ObjectStore: Initialized ObjectStore
19/02/12 18:09:07 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/02/12 18:09:07 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/02/12 18:09:09 INFO HiveMetaStore: Added admin role in metastore
19/02/12 18:09:09 INFO HiveMetaStore: Added public role in metastore
19/02/12 18:09:09 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/02/12 18:09:09 INFO HiveMetaStore: 0: get_all_databases
19/02/12 18:09:09 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_all_databases	
19/02/12 18:09:09 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/02/12 18:09:09 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/02/12 18:09:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/02/12 18:09:10 INFO SessionState: Created HDFS directory: /tmp/hive/erikapat
19/02/12 18:09:10 INFO SessionState: Created local directory: /tmp/erikapat
19/02/12 18:09:10 INFO SessionState: Created local directory: /tmp/c8751ec1-e31f-4b33-936b-377b7048a492_resources
19/02/12 18:09:10 INFO SessionState: Created HDFS directory: /tmp/hive/erikapat/c8751ec1-e31f-4b33-936b-377b7048a492
19/02/12 18:09:10 INFO SessionState: Created local directory: /tmp/erikapat/c8751ec1-e31f-4b33-936b-377b7048a492
19/02/12 18:09:10 INFO SessionState: Created HDFS directory: /tmp/hive/erikapat/c8751ec1-e31f-4b33-936b-377b7048a492/_tmp_space.db
19/02/12 18:09:10 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/erikapat/Dropbox/conento/conento_prueba/PRUEBA%20DATA%20ARQUITECT/Churn.ipynb/spark-warehouse
19/02/12 18:09:10 INFO HiveMetaStore: 0: get_database: default
19/02/12 18:09:10 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_database: default	
19/02/12 18:09:10 INFO HiveMetaStore: 0: get_database: global_temp
19/02/12 18:09:10 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/02/12 18:09:10 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/02/12 18:09:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/02/12 18:09:16 INFO HiveMetaStore: 0: get_database: default
19/02/12 18:09:16 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_database: default	
19/02/12 18:09:16 INFO HiveMetaStore: 0: get_database: default
19/02/12 18:09:16 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_database: default	
19/02/12 18:09:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/02/12 18:09:16 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/02/12 18:09:18 INFO CodeGenerator: Code generated in 644.385535 ms
19/02/12 18:09:18 INFO SparkContext: Starting job: collect at utils.scala:43
19/02/12 18:09:18 INFO DAGScheduler: Got job 0 (collect at utils.scala:43) with 1 output partitions
19/02/12 18:09:18 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:43)
19/02/12 18:09:18 INFO DAGScheduler: Parents of final stage: List()
19/02/12 18:09:18 INFO DAGScheduler: Missing parents: List()
19/02/12 18:09:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:40), which has no missing parents
19/02/12 18:09:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
19/02/12 18:09:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
19/02/12 18:09:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:45409 (size: 4.6 KB, free: 366.3 MB)
19/02/12 18:09:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:40)
19/02/12 18:09:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/02/12 18:09:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
19/02/12 18:09:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/02/12 18:09:19 INFO Executor: Fetching spark://127.0.0.1:34075/jars/sparklyr-2.1-2.11.jar with timestamp 1549991246524
19/02/12 18:09:19 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:34075 after 12 ms (0 ms spent in bootstraps)
19/02/12 18:09:19 INFO Utils: Fetching spark://127.0.0.1:34075/jars/sparklyr-2.1-2.11.jar to /tmp/spark-d3c91b82-dad9-46e7-9965-ff0f4d34a34a/userFiles-dfb7d7c4-ece2-4b46-9330-0c02cfd2b700/fetchFileTemp1445042620889417987.tmp
19/02/12 18:09:19 INFO Executor: Adding file:/tmp/spark-d3c91b82-dad9-46e7-9965-ff0f4d34a34a/userFiles-dfb7d7c4-ece2-4b46-9330-0c02cfd2b700/sparklyr-2.1-2.11.jar to class loader
19/02/12 18:09:19 INFO CodeGenerator: Code generated in 39.942134 ms
19/02/12 18:09:19 INFO CodeGenerator: Code generated in 67.245964 ms
19/02/12 18:09:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
19/02/12 18:09:19 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:43) finished in 0.656 s
19/02/12 18:09:19 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 627 ms on localhost (executor driver) (1/1)
19/02/12 18:09:19 INFO DAGScheduler: Job 0 finished: collect at utils.scala:43, took 1.055617 s
19/02/12 18:09:19 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/02/12 18:09:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:20 INFO SparkSqlParser: Parsing command: iris
19/02/12 18:09:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:20 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
19/02/12 18:09:20 INFO SparkSqlParser: Parsing command: `iris`
19/02/12 18:09:21 INFO CodeGenerator: Code generated in 49.972851 ms
19/02/12 18:09:21 INFO CodeGenerator: Code generated in 32.360071 ms
19/02/12 18:09:21 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/02/12 18:09:21 INFO DAGScheduler: Registering RDD 14 (sql at NativeMethodAccessorImpl.java:0)
19/02/12 18:09:21 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/02/12 18:09:21 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
19/02/12 18:09:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/02/12 18:09:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/02/12 18:09:21 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/02/12 18:09:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 366.3 MB)
19/02/12 18:09:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 366.3 MB)
19/02/12 18:09:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:45409 (size: 8.4 KB, free: 366.3 MB)
19/02/12 18:09:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0)
19/02/12 18:09:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/02/12 18:09:21 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 10001 bytes)
19/02/12 18:09:21 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/02/12 18:09:21 INFO CodeGenerator: Code generated in 39.33671 ms
19/02/12 18:09:21 INFO CodeGenerator: Code generated in 88.798127 ms
19/02/12 18:09:22 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 5.6 KB, free 366.3 MB)
19/02/12 18:09:22 INFO BlockManagerInfo: Added rdd_11_0 in memory on 127.0.0.1:45409 (size: 5.6 KB, free: 366.3 MB)
19/02/12 18:09:22 INFO CodeGenerator: Code generated in 6.426862 ms
19/02/12 18:09:22 INFO CodeGenerator: Code generated in 74.343733 ms
19/02/12 18:09:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2747 bytes result sent to driver
19/02/12 18:09:22 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.645 s
19/02/12 18:09:22 INFO DAGScheduler: looking for newly runnable stages
19/02/12 18:09:22 INFO DAGScheduler: running: Set()
19/02/12 18:09:22 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/02/12 18:09:22 INFO DAGScheduler: failed: Set()
19/02/12 18:09:22 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/02/12 18:09:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 648 ms on localhost (executor driver) (1/1)
19/02/12 18:09:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/02/12 18:09:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
19/02/12 18:09:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
19/02/12 18:09:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:45409 (size: 3.7 KB, free: 366.3 MB)
19/02/12 18:09:22 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0)
19/02/12 18:09:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/02/12 18:09:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5953 bytes)
19/02/12 18:09:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/02/12 18:09:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/02/12 18:09:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 27 ms
19/02/12 18:09:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
19/02/12 18:09:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 154 ms on localhost (executor driver) (1/1)
19/02/12 18:09:22 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.155 s
19/02/12 18:09:22 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 1.004448 s
19/02/12 18:09:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/02/12 18:09:22 INFO CodeGenerator: Code generated in 22.872847 ms
19/02/12 18:09:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:22 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
19/02/12 18:09:22 INFO SparkContext: Starting job: collect at utils.scala:196
19/02/12 18:09:22 INFO DAGScheduler: Registering RDD 21 (collect at utils.scala:196)
19/02/12 18:09:22 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
19/02/12 18:09:22 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
19/02/12 18:09:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/02/12 18:09:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/02/12 18:09:22 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196), which has no missing parents
19/02/12 18:09:22 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.3 KB, free 366.2 MB)
19/02/12 18:09:22 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.5 KB, free 366.2 MB)
19/02/12 18:09:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:45409 (size: 8.5 KB, free: 366.3 MB)
19/02/12 18:09:22 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196)
19/02/12 18:09:22 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/02/12 18:09:22 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 9993 bytes)
19/02/12 18:09:22 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/02/12 18:09:22 INFO BlockManager: Found block rdd_11_0 locally
19/02/12 18:09:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2185 bytes result sent to driver
19/02/12 18:09:23 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.041 s
19/02/12 18:09:23 INFO DAGScheduler: looking for newly runnable stages
19/02/12 18:09:23 INFO DAGScheduler: running: Set()
19/02/12 18:09:23 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/02/12 18:09:23 INFO DAGScheduler: failed: Set()
19/02/12 18:09:23 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196), which has no missing parents
19/02/12 18:09:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 41 ms on localhost (executor driver) (1/1)
19/02/12 18:09:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/02/12 18:09:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.2 MB)
19/02/12 18:09:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.2 MB)
19/02/12 18:09:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:45409 (size: 3.7 KB, free: 366.3 MB)
19/02/12 18:09:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196)
19/02/12 18:09:23 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/02/12 18:09:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 5945 bytes)
19/02/12 18:09:23 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/02/12 18:09:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/02/12 18:09:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/02/12 18:09:23 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
19/02/12 18:09:23 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
19/02/12 18:09:23 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/02/12 18:09:23 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.012 s
19/02/12 18:09:23 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.107026 s
19/02/12 18:09:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz1`
WHERE (0 = 1)
19/02/12 18:09:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:24 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/02/12 18:09:24 INFO HiveMetaStore: 0: get_database: default
19/02/12 18:09:24 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_database: default	
19/02/12 18:09:24 INFO HiveMetaStore: 0: get_database: default
19/02/12 18:09:24 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_database: default	
19/02/12 18:09:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/02/12 18:09:24 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/02/12 18:09:25 INFO SparkContext: Starting job: collect at utils.scala:43
19/02/12 18:09:25 INFO DAGScheduler: Got job 3 (collect at utils.scala:43) with 1 output partitions
19/02/12 18:09:25 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:43)
19/02/12 18:09:25 INFO DAGScheduler: Parents of final stage: List()
19/02/12 18:09:25 INFO DAGScheduler: Missing parents: List()
19/02/12 18:09:25 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:40), which has no missing parents
19/02/12 18:09:25 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.7 KB, free 366.2 MB)
19/02/12 18:09:25 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.2 MB)
19/02/12 18:09:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:45409 (size: 4.6 KB, free: 366.3 MB)
19/02/12 18:09:25 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:40)
19/02/12 18:09:25 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/02/12 18:09:25 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6353 bytes)
19/02/12 18:09:25 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/02/12 18:09:25 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1238 bytes result sent to driver
19/02/12 18:09:25 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 14 ms on localhost (executor driver) (1/1)
19/02/12 18:09:25 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/02/12 18:09:25 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:43) finished in 0.016 s
19/02/12 18:09:25 INFO DAGScheduler: Job 3 finished: collect at utils.scala:43, took 0.047595 s
19/02/12 18:09:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:35 INFO SparkSqlParser: Parsing command: flights
19/02/12 18:09:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:35 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
19/02/12 18:09:35 INFO SparkSqlParser: Parsing command: `flights`
19/02/12 18:09:35 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/02/12 18:09:35 INFO DAGScheduler: Registering RDD 39 (sql at NativeMethodAccessorImpl.java:0)
19/02/12 18:09:35 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/02/12 18:09:35 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
19/02/12 18:09:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
19/02/12 18:09:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
19/02/12 18:09:35 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[39] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/02/12 18:09:35 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 30.7 KB, free 366.2 MB)
19/02/12 18:09:35 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.7 KB, free 366.2 MB)
19/02/12 18:09:35 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:45409 (size: 11.7 KB, free: 366.3 MB)
19/02/12 18:09:35 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[39] at sql at NativeMethodAccessorImpl.java:0)
19/02/12 18:09:35 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/02/12 18:09:37 WARN TaskSetManager: Stage 6 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
19/02/12 18:09:37 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365403 bytes)
19/02/12 18:09:37 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/02/12 18:09:37 INFO ContextCleaner: Cleaned shuffle 0
19/02/12 18:09:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:45409 in memory (size: 8.5 KB, free: 366.3 MB)
19/02/12 18:09:37 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:45409 in memory (size: 3.7 KB, free: 366.3 MB)
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 270
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 271
19/02/12 18:09:37 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:45409 in memory (size: 4.6 KB, free: 366.3 MB)
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 322
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 52
19/02/12 18:09:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:45409 in memory (size: 8.4 KB, free: 366.3 MB)
19/02/12 18:09:37 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:45409 in memory (size: 3.7 KB, free: 366.3 MB)
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 161
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 64
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 63
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 62
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 61
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 60
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 59
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 58
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 57
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 56
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 55
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 54
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 53
19/02/12 18:09:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:45409 in memory (size: 4.6 KB, free: 366.3 MB)
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 1
19/02/12 18:09:37 INFO ContextCleaner: Cleaned accumulator 0
19/02/12 18:09:38 INFO CodeGenerator: Code generated in 70.405044 ms
19/02/12 18:09:39 INFO CodeGenerator: Code generated in 360.333785 ms
19/02/12 18:09:47 INFO MemoryStore: Block rdd_36_0 stored as values in memory (estimated size 22.5 MB, free 343.8 MB)
19/02/12 18:09:47 INFO BlockManagerInfo: Added rdd_36_0 in memory on 127.0.0.1:45409 (size: 22.5 MB, free: 343.8 MB)
19/02/12 18:09:47 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2733 bytes result sent to driver
19/02/12 18:09:47 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 11315 ms on localhost (executor driver) (1/1)
19/02/12 18:09:47 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 11.311 s
19/02/12 18:09:47 INFO DAGScheduler: looking for newly runnable stages
19/02/12 18:09:47 INFO DAGScheduler: running: Set()
19/02/12 18:09:47 INFO DAGScheduler: waiting: Set(ResultStage 7)
19/02/12 18:09:47 INFO DAGScheduler: failed: Set()
19/02/12 18:09:47 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[42] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/02/12 18:09:47 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/02/12 18:09:47 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 343.8 MB)
19/02/12 18:09:47 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 343.7 MB)
19/02/12 18:09:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:45409 (size: 3.7 KB, free: 343.8 MB)
19/02/12 18:09:47 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[42] at sql at NativeMethodAccessorImpl.java:0)
19/02/12 18:09:47 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/02/12 18:09:47 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, ANY, 5953 bytes)
19/02/12 18:09:47 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/02/12 18:09:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/02/12 18:09:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/02/12 18:09:47 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2042 bytes result sent to driver
19/02/12 18:09:47 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 20 ms on localhost (executor driver) (1/1)
19/02/12 18:09:47 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/02/12 18:09:47 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.027 s
19/02/12 18:09:47 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 11.435330 s
19/02/12 18:09:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:47 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
19/02/12 18:09:47 INFO SparkContext: Starting job: collect at utils.scala:196
19/02/12 18:09:47 INFO DAGScheduler: Registering RDD 46 (collect at utils.scala:196)
19/02/12 18:09:47 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
19/02/12 18:09:47 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
19/02/12 18:09:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
19/02/12 18:09:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
19/02/12 18:09:47 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[46] at collect at utils.scala:196), which has no missing parents
19/02/12 18:09:47 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 30.7 KB, free 343.7 MB)
19/02/12 18:09:47 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.8 KB, free 343.7 MB)
19/02/12 18:09:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:45409 (size: 11.8 KB, free: 343.8 MB)
19/02/12 18:09:47 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[46] at collect at utils.scala:196)
19/02/12 18:09:47 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/02/12 18:09:47 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:45409 in memory (size: 3.7 KB, free: 343.8 MB)
19/02/12 18:09:47 INFO ContextCleaner: Cleaned accumulator 431
19/02/12 18:09:47 WARN TaskSetManager: Stage 8 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
19/02/12 18:09:47 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365396 bytes)
19/02/12 18:09:47 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/02/12 18:09:48 INFO BlockManager: Found block rdd_36_0 locally
19/02/12 18:09:48 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2098 bytes result sent to driver
19/02/12 18:09:48 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 842 ms on localhost (executor driver) (1/1)
19/02/12 18:09:48 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/02/12 18:09:48 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.842 s
19/02/12 18:09:48 INFO DAGScheduler: looking for newly runnable stages
19/02/12 18:09:48 INFO DAGScheduler: running: Set()
19/02/12 18:09:48 INFO DAGScheduler: waiting: Set(ResultStage 9)
19/02/12 18:09:48 INFO DAGScheduler: failed: Set()
19/02/12 18:09:48 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[49] at collect at utils.scala:196), which has no missing parents
19/02/12 18:09:48 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 343.7 MB)
19/02/12 18:09:48 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 343.7 MB)
19/02/12 18:09:48 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:45409 (size: 3.7 KB, free: 343.8 MB)
19/02/12 18:09:48 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[49] at collect at utils.scala:196)
19/02/12 18:09:48 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/02/12 18:09:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 5946 bytes)
19/02/12 18:09:48 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/02/12 18:09:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/02/12 18:09:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/02/12 18:09:48 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2042 bytes result sent to driver
19/02/12 18:09:48 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 29 ms on localhost (executor driver) (1/1)
19/02/12 18:09:48 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/02/12 18:09:48 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.033 s
19/02/12 18:09:48 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.901647 s
19/02/12 18:09:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
19/02/12 18:09:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/02/12 18:09:48 INFO HiveMetaStore: 0: get_database: default
19/02/12 18:09:48 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_database: default	
19/02/12 18:09:48 INFO HiveMetaStore: 0: get_database: default
19/02/12 18:09:48 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_database: default	
19/02/12 18:09:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/02/12 18:09:48 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/02/12 18:09:48 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:45409 in memory (size: 3.7 KB, free: 343.8 MB)
19/02/12 18:09:48 INFO SparkContext: Starting job: collect at utils.scala:43
19/02/12 18:09:48 INFO DAGScheduler: Got job 6 (collect at utils.scala:43) with 1 output partitions
19/02/12 18:09:48 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:43)
19/02/12 18:09:48 INFO DAGScheduler: Parents of final stage: List()
19/02/12 18:09:48 INFO DAGScheduler: Missing parents: List()
19/02/12 18:09:48 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[55] at map at utils.scala:40), which has no missing parents
19/02/12 18:09:48 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.7 KB, free 343.7 MB)
19/02/12 18:09:48 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.6 KB, free 343.7 MB)
19/02/12 18:09:48 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:45409 (size: 4.6 KB, free: 343.8 MB)
19/02/12 18:09:48 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[55] at map at utils.scala:40)
19/02/12 18:09:48 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/02/12 18:09:48 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6408 bytes)
19/02/12 18:09:48 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
19/02/12 18:09:49 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1248 bytes result sent to driver
19/02/12 18:09:49 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 25 ms on localhost (executor driver) (1/1)
19/02/12 18:09:49 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/02/12 18:09:49 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:43) finished in 0.030 s
19/02/12 18:09:49 INFO DAGScheduler: Job 6 finished: collect at utils.scala:43, took 0.072207 s
19/02/12 18:09:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:50 INFO SparkSqlParser: Parsing command: batting
19/02/12 18:09:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:51 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
19/02/12 18:09:51 INFO SparkSqlParser: Parsing command: `batting`
19/02/12 18:09:51 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/02/12 18:09:51 INFO DAGScheduler: Registering RDD 64 (sql at NativeMethodAccessorImpl.java:0)
19/02/12 18:09:51 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/02/12 18:09:51 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
19/02/12 18:09:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
19/02/12 18:09:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
19/02/12 18:09:51 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/02/12 18:09:51 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 31.9 KB, free 343.7 MB)
19/02/12 18:09:51 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 11.7 KB, free 343.7 MB)
19/02/12 18:09:51 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:45409 (size: 11.7 KB, free: 343.8 MB)
19/02/12 18:09:51 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0)
19/02/12 18:09:51 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/02/12 18:09:51 WARN TaskSetManager: Stage 11 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
19/02/12 18:09:51 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814099 bytes)
19/02/12 18:09:51 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
19/02/12 18:09:51 INFO CodeGenerator: Code generated in 17.840235 ms
19/02/12 18:09:51 INFO CodeGenerator: Code generated in 104.775862 ms
19/02/12 18:09:52 INFO ContextCleaner: Cleaned accumulator 540
19/02/12 18:09:52 INFO ContextCleaner: Cleaned accumulator 541
19/02/12 18:09:52 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:45409 in memory (size: 4.6 KB, free: 343.8 MB)
19/02/12 18:09:52 INFO ContextCleaner: Cleaned accumulator 592
19/02/12 18:09:53 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:45409 in memory (size: 11.8 KB, free: 343.8 MB)
19/02/12 18:09:53 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:45409 in memory (size: 11.7 KB, free: 343.8 MB)
19/02/12 18:09:53 INFO ContextCleaner: Cleaned shuffle 2
19/02/12 18:09:53 INFO ContextCleaner: Cleaned accumulator 334
19/02/12 18:09:53 INFO ContextCleaner: Cleaned accumulator 333
19/02/12 18:09:53 INFO ContextCleaner: Cleaned accumulator 332
19/02/12 18:09:53 INFO ContextCleaner: Cleaned accumulator 331
19/02/12 18:09:53 INFO ContextCleaner: Cleaned accumulator 330
19/02/12 18:09:53 INFO ContextCleaner: Cleaned accumulator 329
19/02/12 18:09:53 INFO ContextCleaner: Cleaned accumulator 328
19/02/12 18:09:53 INFO ContextCleaner: Cleaned accumulator 327
19/02/12 18:09:53 INFO ContextCleaner: Cleaned accumulator 326
19/02/12 18:09:53 INFO ContextCleaner: Cleaned accumulator 325
19/02/12 18:09:53 INFO ContextCleaner: Cleaned accumulator 324
19/02/12 18:09:53 INFO ContextCleaner: Cleaned accumulator 323
19/02/12 18:09:55 INFO MemoryStore: Block rdd_61_0 stored as values in memory (estimated size 3.3 MB, free 340.4 MB)
19/02/12 18:09:55 INFO BlockManagerInfo: Added rdd_61_0 in memory on 127.0.0.1:45409 (size: 3.3 MB, free: 340.5 MB)
19/02/12 18:09:55 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2733 bytes result sent to driver
19/02/12 18:09:55 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 3923 ms on localhost (executor driver) (1/1)
19/02/12 18:09:55 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/02/12 18:09:55 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 3.914 s
19/02/12 18:09:55 INFO DAGScheduler: looking for newly runnable stages
19/02/12 18:09:55 INFO DAGScheduler: running: Set()
19/02/12 18:09:55 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/02/12 18:09:55 INFO DAGScheduler: failed: Set()
19/02/12 18:09:55 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[67] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/02/12 18:09:55 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.0 KB, free 340.4 MB)
19/02/12 18:09:55 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.4 MB)
19/02/12 18:09:55 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:45409 (size: 3.7 KB, free: 340.5 MB)
19/02/12 18:09:55 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[67] at sql at NativeMethodAccessorImpl.java:0)
19/02/12 18:09:55 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/02/12 18:09:55 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, ANY, 5954 bytes)
19/02/12 18:09:55 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
19/02/12 18:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/02/12 18:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/02/12 18:09:55 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2042 bytes result sent to driver
19/02/12 18:09:55 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 11 ms on localhost (executor driver) (1/1)
19/02/12 18:09:55 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/02/12 18:09:55 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.003 s
19/02/12 18:09:55 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 3.953353 s
19/02/12 18:09:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:55 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
19/02/12 18:09:55 INFO SparkContext: Starting job: collect at utils.scala:196
19/02/12 18:09:55 INFO DAGScheduler: Registering RDD 71 (collect at utils.scala:196)
19/02/12 18:09:55 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
19/02/12 18:09:55 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
19/02/12 18:09:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
19/02/12 18:09:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
19/02/12 18:09:55 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[71] at collect at utils.scala:196), which has no missing parents
19/02/12 18:09:55 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 31.9 KB, free 340.4 MB)
19/02/12 18:09:55 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 11.7 KB, free 340.4 MB)
19/02/12 18:09:55 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:45409 (size: 11.7 KB, free: 340.4 MB)
19/02/12 18:09:55 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[71] at collect at utils.scala:196)
19/02/12 18:09:55 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/02/12 18:09:55 WARN TaskSetManager: Stage 13 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
19/02/12 18:09:55 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814091 bytes)
19/02/12 18:09:55 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
19/02/12 18:09:55 INFO BlockManager: Found block rdd_61_0 locally
19/02/12 18:09:55 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2185 bytes result sent to driver
19/02/12 18:09:55 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 275 ms on localhost (executor driver) (1/1)
19/02/12 18:09:55 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/02/12 18:09:55 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.275 s
19/02/12 18:09:55 INFO DAGScheduler: looking for newly runnable stages
19/02/12 18:09:55 INFO DAGScheduler: running: Set()
19/02/12 18:09:55 INFO DAGScheduler: waiting: Set(ResultStage 14)
19/02/12 18:09:55 INFO DAGScheduler: failed: Set()
19/02/12 18:09:55 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[74] at collect at utils.scala:196), which has no missing parents
19/02/12 18:09:55 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.0 KB, free 340.4 MB)
19/02/12 18:09:55 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KB, free 340.4 MB)
19/02/12 18:09:55 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:45409 (size: 3.7 KB, free: 340.4 MB)
19/02/12 18:09:55 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[74] at collect at utils.scala:196)
19/02/12 18:09:55 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/02/12 18:09:55 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, ANY, 5946 bytes)
19/02/12 18:09:55 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
19/02/12 18:09:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/02/12 18:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/02/12 18:09:55 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 2042 bytes result sent to driver
19/02/12 18:09:55 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 13 ms on localhost (executor driver) (1/1)
19/02/12 18:09:55 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/02/12 18:09:55 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.012 s
19/02/12 18:09:55 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.313852 s
19/02/12 18:09:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting` AS `zzz3`
WHERE (0 = 1)
19/02/12 18:09:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:09:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/02/12 18:09:55 INFO HiveMetaStore: 0: get_database: default
19/02/12 18:09:55 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_database: default	
19/02/12 18:09:55 INFO HiveMetaStore: 0: get_database: default
19/02/12 18:09:55 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_database: default	
19/02/12 18:09:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/02/12 18:09:55 INFO audit: ugi=erikapat	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/02/12 18:09:55 INFO SparkContext: Starting job: collect at utils.scala:43
19/02/12 18:09:55 INFO DAGScheduler: Got job 9 (collect at utils.scala:43) with 1 output partitions
19/02/12 18:09:55 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:43)
19/02/12 18:09:55 INFO DAGScheduler: Parents of final stage: List()
19/02/12 18:09:55 INFO DAGScheduler: Missing parents: List()
19/02/12 18:09:55 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[80] at map at utils.scala:40), which has no missing parents
19/02/12 18:09:55 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 8.7 KB, free 340.4 MB)
19/02/12 18:09:55 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.6 KB, free 340.4 MB)
19/02/12 18:09:55 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:45409 (size: 4.6 KB, free: 340.4 MB)
19/02/12 18:09:55 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
19/02/12 18:09:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[80] at map at utils.scala:40)
19/02/12 18:09:55 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/02/12 18:09:55 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6462 bytes)
19/02/12 18:09:55 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
19/02/12 18:09:55 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1258 bytes result sent to driver
19/02/12 18:09:55 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 7 ms on localhost (executor driver) (1/1)
19/02/12 18:09:55 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/02/12 18:09:55 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:43) finished in 0.008 s
19/02/12 18:09:55 INFO DAGScheduler: Job 9 finished: collect at utils.scala:43, took 0.018805 s
19/02/12 18:16:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:16:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/02/12 18:16:52 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:45409 in memory (size: 4.6 KB, free: 340.4 MB)
19/02/12 18:16:53 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:45409 in memory (size: 3.7 KB, free: 340.4 MB)
19/02/12 18:16:53 INFO ContextCleaner: Cleaned accumulator 701
19/02/12 18:16:53 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:45409 in memory (size: 11.7 KB, free: 340.5 MB)
19/02/12 18:16:53 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:45409 in memory (size: 3.7 KB, free: 340.5 MB)
19/02/12 18:16:53 INFO ContextCleaner: Cleaned accumulator 810
19/02/12 18:16:53 INFO ContextCleaner: Cleaned accumulator 811
19/02/12 18:16:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:16:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 10
19/02/12 18:16:53 INFO InMemoryTableScanExec: Predicate isnotnull(dep_delay#175) generates partition filter: ((dep_delay.count#1203 - dep_delay.nullCount#1202) > 0)
19/02/12 18:16:53 INFO InMemoryTableScanExec: Predicate (dep_delay#175 = 2.0) generates partition filter: ((dep_delay.lowerBound#1201 <= 2.0) && (2.0 <= dep_delay.upperBound#1200))
19/02/12 18:16:53 INFO CodeGenerator: Code generated in 60.106775 ms
19/02/12 18:16:53 INFO SparkContext: Starting job: collect at utils.scala:196
19/02/12 18:16:53 INFO DAGScheduler: Got job 10 (collect at utils.scala:196) with 1 output partitions
19/02/12 18:16:53 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:196)
19/02/12 18:16:53 INFO DAGScheduler: Parents of final stage: List()
19/02/12 18:16:53 INFO DAGScheduler: Missing parents: List()
19/02/12 18:16:53 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[83] at collect at utils.scala:196), which has no missing parents
19/02/12 18:16:53 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 34.7 KB, free 340.4 MB)
19/02/12 18:16:53 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 12.6 KB, free 340.4 MB)
19/02/12 18:16:53 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:45409 (size: 12.6 KB, free: 340.5 MB)
19/02/12 18:16:53 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
19/02/12 18:16:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[83] at collect at utils.scala:196)
19/02/12 18:16:53 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/02/12 18:16:53 WARN TaskSetManager: Stage 16 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
19/02/12 18:16:53 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365321 bytes)
19/02/12 18:16:53 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
19/02/12 18:16:54 INFO BlockManager: Found block rdd_36_0 locally
19/02/12 18:16:54 INFO CodeGenerator: Code generated in 18.878958 ms
19/02/12 18:16:54 INFO CodeGenerator: Code generated in 167.007222 ms
19/02/12 18:16:54 WARN Executor: 1 block locks were not released by TID = 16:
[rdd_36_0]
19/02/12 18:16:54 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 2495 bytes result sent to driver
19/02/12 18:16:54 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 1259 ms on localhost (executor driver) (1/1)
19/02/12 18:16:54 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/02/12 18:16:54 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:196) finished in 1.259 s
19/02/12 18:16:54 INFO DAGScheduler: Job 10 finished: collect at utils.scala:196, took 1.290421 s
19/02/12 18:16:54 INFO CodeGenerator: Code generated in 33.776814 ms
19/02/12 18:17:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:17:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `sephhpmokq`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/02/12 18:17:24 INFO CodeGenerator: Code generated in 27.438087 ms
19/02/12 18:17:24 INFO CodeGenerator: Code generated in 139.78218 ms
19/02/12 18:17:24 INFO SparkContext: Starting job: collect at utils.scala:196
19/02/12 18:17:24 INFO DAGScheduler: Registering RDD 86 (collect at utils.scala:196)
19/02/12 18:17:24 INFO DAGScheduler: Got job 11 (collect at utils.scala:196) with 4 output partitions
19/02/12 18:17:24 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:196)
19/02/12 18:17:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
19/02/12 18:17:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
19/02/12 18:17:24 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[86] at collect at utils.scala:196), which has no missing parents
19/02/12 18:17:25 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 50.3 KB, free 340.3 MB)
19/02/12 18:17:25 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 20.0 KB, free 340.3 MB)
19/02/12 18:17:25 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:45409 (size: 20.0 KB, free: 340.4 MB)
19/02/12 18:17:25 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
19/02/12 18:17:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[86] at collect at utils.scala:196)
19/02/12 18:17:25 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/02/12 18:17:25 INFO ContextCleaner: Cleaned accumulator 911
19/02/12 18:17:25 WARN TaskSetManager: Stage 17 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
19/02/12 18:17:25 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365396 bytes)
19/02/12 18:17:25 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
19/02/12 18:17:25 INFO BlockManager: Found block rdd_36_0 locally
19/02/12 18:17:25 INFO CodeGenerator: Code generated in 20.036959 ms
19/02/12 18:17:25 INFO CodeGenerator: Code generated in 20.529614 ms
19/02/12 18:17:25 INFO CodeGenerator: Code generated in 12.815564 ms
19/02/12 18:17:26 INFO CodeGenerator: Code generated in 25.734038 ms
19/02/12 18:17:26 INFO CodeGenerator: Code generated in 49.740761 ms
19/02/12 18:17:26 INFO CodeGenerator: Code generated in 53.435894 ms
19/02/12 18:17:26 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2442 bytes result sent to driver
19/02/12 18:17:26 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 1861 ms on localhost (executor driver) (1/1)
19/02/12 18:17:26 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/02/12 18:17:26 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:196) finished in 1.861 s
19/02/12 18:17:26 INFO DAGScheduler: looking for newly runnable stages
19/02/12 18:17:26 INFO DAGScheduler: running: Set()
19/02/12 18:17:26 INFO DAGScheduler: waiting: Set(ResultStage 18)
19/02/12 18:17:26 INFO DAGScheduler: failed: Set()
19/02/12 18:17:26 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[89] at collect at utils.scala:196), which has no missing parents
19/02/12 18:17:26 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 27.3 KB, free 340.3 MB)
19/02/12 18:17:26 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.7 KB, free 340.3 MB)
19/02/12 18:17:26 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:45409 (size: 11.7 KB, free: 340.4 MB)
19/02/12 18:17:26 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
19/02/12 18:17:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[89] at collect at utils.scala:196)
19/02/12 18:17:26 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
19/02/12 18:17:26 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, ANY, 5946 bytes)
19/02/12 18:17:26 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 19, localhost, executor driver, partition 1, ANY, 5946 bytes)
19/02/12 18:17:26 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 20, localhost, executor driver, partition 2, ANY, 5946 bytes)
19/02/12 18:17:26 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 21, localhost, executor driver, partition 3, ANY, 5946 bytes)
19/02/12 18:17:26 INFO Executor: Running task 1.0 in stage 18.0 (TID 19)
19/02/12 18:17:26 INFO Executor: Running task 2.0 in stage 18.0 (TID 20)
19/02/12 18:17:26 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
19/02/12 18:17:26 INFO Executor: Running task 3.0 in stage 18.0 (TID 21)
19/02/12 18:17:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/02/12 18:17:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
19/02/12 18:17:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/02/12 18:17:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
19/02/12 18:17:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/02/12 18:17:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/02/12 18:17:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/02/12 18:17:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/02/12 18:17:27 INFO Executor: Finished task 2.0 in stage 18.0 (TID 20). 23246 bytes result sent to driver
19/02/12 18:17:27 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 22143 bytes result sent to driver
19/02/12 18:17:27 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 20) in 112 ms on localhost (executor driver) (1/4)
19/02/12 18:17:27 INFO Executor: Finished task 3.0 in stage 18.0 (TID 21). 21386 bytes result sent to driver
19/02/12 18:17:27 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 114 ms on localhost (executor driver) (2/4)
19/02/12 18:17:27 INFO Executor: Finished task 1.0 in stage 18.0 (TID 19). 22319 bytes result sent to driver
19/02/12 18:17:27 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 21) in 116 ms on localhost (executor driver) (3/4)
19/02/12 18:17:27 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 19) in 120 ms on localhost (executor driver) (4/4)
19/02/12 18:17:27 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/02/12 18:17:27 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:196) finished in 0.095 s
19/02/12 18:17:27 INFO DAGScheduler: Job 11 finished: collect at utils.scala:196, took 2.019069 s
19/02/12 18:17:27 INFO CodeGenerator: Code generated in 17.001763 ms
19/02/12 18:18:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:18:12 INFO SparkSqlParser: Parsing command: SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`, rank() OVER (PARTITION BY `playerID` ORDER BY `H` DESC) AS `zzz4`
FROM (SELECT *
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`) `zleoswpbcr`
ORDER BY `playerID`, `yearID`, `teamID`) `yawlkuorpg`) `liwkdqbbxk`
WHERE (`zzz4` <= 2,0 AND `H` > 0,0)
19/02/12 18:18:12 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:45409 in memory (size: 11.7 KB, free: 340.4 MB)
19/02/12 18:19:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:19:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting`
LIMIT 6
19/02/12 18:19:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:19:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting`
LIMIT 6
19/02/12 18:19:36 INFO SparkContext: Starting job: collect at utils.scala:196
19/02/12 18:19:36 INFO DAGScheduler: Got job 12 (collect at utils.scala:196) with 1 output partitions
19/02/12 18:19:36 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:196)
19/02/12 18:19:36 INFO DAGScheduler: Parents of final stage: List()
19/02/12 18:19:36 INFO DAGScheduler: Missing parents: List()
19/02/12 18:19:36 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[91] at collect at utils.scala:196), which has no missing parents
19/02/12 18:19:36 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 27.6 KB, free 340.3 MB)
19/02/12 18:19:36 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 9.7 KB, free 340.3 MB)
19/02/12 18:19:36 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:45409 (size: 9.7 KB, free: 340.4 MB)
19/02/12 18:19:36 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
19/02/12 18:19:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[91] at collect at utils.scala:196)
19/02/12 18:19:36 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/02/12 18:19:36 WARN TaskSetManager: Stage 19 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
19/02/12 18:19:36 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814016 bytes)
19/02/12 18:19:36 INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
19/02/12 18:19:36 INFO BlockManager: Found block rdd_61_0 locally
19/02/12 18:19:36 INFO CodeGenerator: Code generated in 29.399899 ms
19/02/12 18:19:36 WARN Executor: 1 block locks were not released by TID = 22:
[rdd_61_0]
19/02/12 18:19:36 INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 1880 bytes result sent to driver
19/02/12 18:19:36 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 298 ms on localhost (executor driver) (1/1)
19/02/12 18:19:36 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/02/12 18:19:36 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:196) finished in 0.289 s
19/02/12 18:19:36 INFO DAGScheduler: Job 12 finished: collect at utils.scala:196, took 0.325287 s
19/02/12 18:19:36 INFO CodeGenerator: Code generated in 16.067851 ms
19/02/12 18:20:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:20:11 INFO SparkSqlParser: Parsing command: SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`
ORDER BY `playerID`, `yearID`, `teamID`
19/02/12 18:20:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:20:11 INFO SparkSqlParser: Parsing command: SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`
ORDER BY `playerID`, `yearID`, `teamID`
LIMIT 10
19/02/12 18:20:11 INFO CodeGenerator: Code generated in 20.570743 ms
19/02/12 18:20:11 INFO SparkContext: Starting job: collect at utils.scala:196
19/02/12 18:20:11 INFO DAGScheduler: Got job 13 (collect at utils.scala:196) with 1 output partitions
19/02/12 18:20:11 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:196)
19/02/12 18:20:11 INFO DAGScheduler: Parents of final stage: List()
19/02/12 18:20:11 INFO DAGScheduler: Missing parents: List()
19/02/12 18:20:11 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[94] at collect at utils.scala:196), which has no missing parents
19/02/12 18:20:11 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 29.2 KB, free 340.3 MB)
19/02/12 18:20:11 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 10.3 KB, free 340.2 MB)
19/02/12 18:20:11 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:45409 (size: 10.3 KB, free: 340.4 MB)
19/02/12 18:20:11 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
19/02/12 18:20:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[94] at collect at utils.scala:196)
19/02/12 18:20:11 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/02/12 18:20:11 WARN TaskSetManager: Stage 20 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
19/02/12 18:20:11 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814106 bytes)
19/02/12 18:20:11 INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
19/02/12 18:20:11 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:45409 in memory (size: 9.7 KB, free: 340.4 MB)
19/02/12 18:20:11 INFO BlockManager: Found block rdd_61_0 locally
19/02/12 18:20:11 INFO CodeGenerator: Code generated in 20.591436 ms
19/02/12 18:20:11 INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 4129 bytes result sent to driver
19/02/12 18:20:11 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 516 ms on localhost (executor driver) (1/1)
19/02/12 18:20:11 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/02/12 18:20:11 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:196) finished in 0.504 s
19/02/12 18:20:11 INFO DAGScheduler: Job 13 finished: collect at utils.scala:196, took 0.579914 s
19/02/12 18:20:12 INFO CodeGenerator: Code generated in 8.705994 ms
19/02/12 18:20:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:20:44 INFO SparkSqlParser: Parsing command: SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`, rank() OVER (PARTITION BY `playerID` ORDER BY `H` DESC) AS `zzz5`
FROM (SELECT *
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`) `vuanveddtj`
ORDER BY `playerID`, `yearID`, `teamID`) `skhqbkstmf`) `ehqrbcytnm`
WHERE ((`zzz5` <= 2,0) AND (`H` > 0,0))
19/02/12 18:21:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:21:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT *
FROM (SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`) `hxqlupczng`
ORDER BY `playerID`, `yearID`, `teamID`) `nygdmpwupu`
WHERE (`H` > 0,0)
19/02/12 18:21:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:21:15 INFO SparkSqlParser: Parsing command: SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`
ORDER BY `playerID`, `yearID`, `teamID`
19/02/12 18:21:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:21:15 INFO SparkSqlParser: Parsing command: SELECT `playerID`, `yearID`, `teamID`, `G`, `AB`, `R`, `H`
FROM `batting`
ORDER BY `playerID`, `yearID`, `teamID`
LIMIT 10
19/02/12 18:21:15 INFO SparkContext: Starting job: collect at utils.scala:196
19/02/12 18:21:15 INFO DAGScheduler: Got job 14 (collect at utils.scala:196) with 1 output partitions
19/02/12 18:21:15 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:196)
19/02/12 18:21:15 INFO DAGScheduler: Parents of final stage: List()
19/02/12 18:21:15 INFO DAGScheduler: Missing parents: List()
19/02/12 18:21:15 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[97] at collect at utils.scala:196), which has no missing parents
19/02/12 18:21:15 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 29.2 KB, free 340.3 MB)
19/02/12 18:21:15 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 10.3 KB, free 340.2 MB)
19/02/12 18:21:15 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:45409 (size: 10.3 KB, free: 340.4 MB)
19/02/12 18:21:15 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
19/02/12 18:21:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[97] at collect at utils.scala:196)
19/02/12 18:21:15 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/02/12 18:21:15 WARN TaskSetManager: Stage 21 contains a task of very large size (6654 KB). The maximum recommended task size is 100 KB.
19/02/12 18:21:15 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 6814107 bytes)
19/02/12 18:21:15 INFO Executor: Running task 0.0 in stage 21.0 (TID 24)
19/02/12 18:21:15 INFO BlockManager: Found block rdd_61_0 locally
19/02/12 18:21:15 INFO Executor: Finished task 0.0 in stage 21.0 (TID 24). 3969 bytes result sent to driver
19/02/12 18:21:15 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 24) in 339 ms on localhost (executor driver) (1/1)
19/02/12 18:21:15 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/02/12 18:21:15 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:196) finished in 0.331 s
19/02/12 18:21:15 INFO DAGScheduler: Job 14 finished: collect at utils.scala:196, took 0.362504 s
19/02/12 18:23:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
19/02/12 18:23:46 INFO SparkSqlParser: Parsing command: SELECT * FROM iris LIMIT 10
19/02/12 18:23:46 INFO SparkContext: Starting job: collect at utils.scala:196
19/02/12 18:23:46 INFO DAGScheduler: Got job 15 (collect at utils.scala:196) with 1 output partitions
19/02/12 18:23:46 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:196)
19/02/12 18:23:46 INFO DAGScheduler: Parents of final stage: List()
19/02/12 18:23:46 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:45409 in memory (size: 10.3 KB, free: 340.4 MB)
19/02/12 18:23:46 INFO DAGScheduler: Missing parents: List()
19/02/12 18:23:46 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[99] at collect at utils.scala:196), which has no missing parents
19/02/12 18:23:46 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 14.0 KB, free 340.3 MB)
19/02/12 18:23:46 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 6.5 KB, free 340.3 MB)
19/02/12 18:23:46 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:45409 (size: 6.5 KB, free: 340.4 MB)
19/02/12 18:23:46 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
19/02/12 18:23:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[99] at collect at utils.scala:196)
19/02/12 18:23:46 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/02/12 18:23:46 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 9920 bytes)
19/02/12 18:23:46 INFO Executor: Running task 0.0 in stage 22.0 (TID 25)
19/02/12 18:23:46 INFO BlockManager: Found block rdd_11_0 locally
19/02/12 18:23:46 INFO CodeGenerator: Code generated in 14.992692 ms
19/02/12 18:23:46 WARN Executor: 1 block locks were not released by TID = 25:
[rdd_11_0]
19/02/12 18:23:46 INFO Executor: Finished task 0.0 in stage 22.0 (TID 25). 1653 bytes result sent to driver
19/02/12 18:23:46 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 25) in 65 ms on localhost (executor driver) (1/1)
19/02/12 18:23:46 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/02/12 18:23:46 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:196) finished in 0.065 s
19/02/12 18:23:46 INFO DAGScheduler: Job 15 finished: collect at utils.scala:196, took 0.134455 s
19/02/12 18:23:46 INFO CodeGenerator: Code generated in 25.240651 ms
19/02/12 18:37:27 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:45409 in memory (size: 20.0 KB, free: 340.4 MB)
19/02/12 18:37:27 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:45409 in memory (size: 6.5 KB, free: 340.4 MB)
19/02/12 18:37:27 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:45409 in memory (size: 10.3 KB, free: 340.5 MB)
19/02/12 18:37:27 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:45409 in memory (size: 12.6 KB, free: 340.5 MB)
19/02/12 18:37:27 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:45409 in memory (size: 11.7 KB, free: 340.5 MB)
19/02/12 18:37:27 INFO ContextCleaner: Cleaned shuffle 4
19/02/12 18:37:27 INFO ContextCleaner: Cleaned accumulator 604
19/02/12 18:37:27 INFO ContextCleaner: Cleaned accumulator 603
19/02/12 18:37:27 INFO ContextCleaner: Cleaned accumulator 602
19/02/12 18:37:27 INFO ContextCleaner: Cleaned accumulator 601
19/02/12 18:37:27 INFO ContextCleaner: Cleaned accumulator 600
19/02/12 18:37:27 INFO ContextCleaner: Cleaned accumulator 599
19/02/12 18:37:27 INFO ContextCleaner: Cleaned accumulator 598
19/02/12 18:37:27 INFO ContextCleaner: Cleaned accumulator 597
19/02/12 18:37:27 INFO ContextCleaner: Cleaned accumulator 596
19/02/12 18:37:27 INFO ContextCleaner: Cleaned accumulator 595
19/02/12 18:37:27 INFO ContextCleaner: Cleaned accumulator 594
19/02/12 18:37:27 INFO ContextCleaner: Cleaned accumulator 593
