
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Deep\_learning\_intro}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{deep-learning-tutorial}{%
\subsection{DEEP LEARNING TUTORIAL}\label{deep-learning-tutorial}}

This tutorial covers several major aspects of neural networks by
providing working nets coded in Keras, a minimalist and efficient Python
library for deep learning computations running on the top of either
Google's TensorFlow or University of Montreal's Theano backend. So,
let's star For the algorithms of deep learning the packages that are
required are:

\begin{itemize}
\tightlist
\item
  TensorFlow 1.0.0 or higher
\item
  Keras 2.0.2 or higher
\item
  Matplotlib 1.5.3 or higher
\item
  Scikit-learn 0.18.1 or higher
\item
  NumPy 1.12.1 or higher
\end{itemize}

\hypertarget{some-of-the-mos-known-arquitectures}{%
\paragraph{Some of the mos known
arquitectures:}\label{some-of-the-mos-known-arquitectures}}

\begin{itemize}
\tightlist
\item
  Perceptron: is a model having one single linear layer
\item
  Multilayer perceptron: is a model having multiple layers
\item
  Activation functions
\item
  Gradient descent
\item
  Stochastic gradient descent
\item
  Backpropagation
\end{itemize}

More in:
https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464

\hypertarget{optimization-functions}{%
\paragraph{Optimization functions}\label{optimization-functions}}

\begin{itemize}
\item
  A common problem we all face when working on deep learning projects is
  choosing a learning rate and optimizer (the hyper-parameters).
\item
  In keras we have 6 different optimizers: Gradient Descent, Adam,
  Adagrad, Adadelta, RMS Prop and Momentum.
\item
  gradient + momentum: fuerza hacia lam isma dirección de decrecimiento,
  evita oscilaciones hacia arriba y hacia abajo.
\item
  Rprop truncamientos hacia arriba y hacia abajo para evitar
  oscilaciones (método adaptativo)
\item
  RMS prop: tiene un factor de memoria para recordar una mejora con
  respecto a R prop.
\item
  Adam learns the fastest. Adam is more stable than the other
  optimizers, it doesn't suffer any major decreases in accuracy.
\item
  \textbf{Momentum vs.~Learning rate tradeoff}
\item
  \textbf{Learnign rate:}
\item
  There is a valley shape for each optimizer: too low a learning rate
  never progresses, too high a learning rate causes instability and
  never converges. In between there is a band of ``just right'' learning
  rates that successfully train.
\item
  There is no learning rate that works for all optimizers.
\item
  Learning rate can affect training time by an order of magnitude.
\item
  It's crucial you choose the correct learning rate as otherwise your
  network will either fail to train, or take much longer to converge.
\end{itemize}

https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1

\hypertarget{activation-functions}{%
\paragraph{Activation functions}\label{activation-functions}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Linear Activation Function}: It is a simple linear function of
  the form f(x) = x. Basically, the input passes to the output without
  any modification.
\item
  \textbf{Non-Linear Activation Functions:} These functions are used to
  separate the data that is not linearly separable and are the most used
  activation functions. Few examples of different types of non-linear
  activation functions are sigmoid, tanh, relu, lrelu, prelu, swish,
  etc.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    \textbf{Sigmoid}: It is also known as Logistic Activation Function.
    It takes a real-valued number and squashes it into a range between 0
    and 1. It is also used in the output layer where our end goal is to
    predict probability. It converts large negative numbers to 0 and
    large positive numbers to 1.
  \end{enumerate}
\end{enumerate}

\textbf{The three major drawbacks of sigmoid are:}

\begin{itemize}
\item
  \textbf{Vanishing gradients:} Notice, the sigmoid function is flat
  near 0 and 1. In other words, the gradient of the sigmoid is 0 near 0
  and 1. During backpropagation through the network with sigmoid
  activation, the gradients in neurons whose output is near 0 or 1 are
  nearly 0. These neurons are called saturated neurons. Thus, the
  weights in these neurons do not update. Not only that, the weights of
  neurons connected to such neurons are also slowly updated. This
  problem is also known as vanishing gradient. So, imagine if there was
  a large network comprising of sigmoid neurons in which many of them
  are in a saturated regime, then the network will not be able to
  backpropagate.
\item
  \textbf{Not zero centered:} Sigmoid outputs are not zero-centered.
\item
  \textbf{Computationally expensive:} The exp() function is
  computationally expensive compared with the other non-linear
  activation functions.

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{1}
  \tightlist
  \item
    \textbf{Tanh} You can think of a tanh function as two sigmoids put
    together. In practice, tanh is preferable over sigmoid. The negative
    inputs considered as strongly negative, zero input values mapped
    near zero, and the positive inputs regarded as positive. The only
    drawback of tanh is that the tanh function also suffers from the
    vanishing gradient problem and therefore kills gradients when
    saturated.
  \end{enumerate}
\end{itemize}

To address the vanishing gradient problem, let us discuss another
non-linear activation function known as the rectified linear unit (ReLU)
which is a lot better than the previous two activation functions and is
most widely used these days.

    \textbf{Rectified Linear Unit (ReLU)}

ReLU is half-rectified from the bottom as you can see from the figure
above. Mathematically, it is given by this simple expression

\begin{verbatim}
\[ f(x) = \max(0,x) \]
\end{verbatim}

This means that when the input x \textless{} 0 the output is 0 and if x
\textgreater{} 0 the output is x. This activation makes the network
converge much faster. It does not saturate which means it is resistant
to the vanishing gradient problem at least in the positive region ( when
x \textgreater{} 0), so the neurons do not backpropagate all zeros at
least in half of their regions. ReLU is computationally very efficient
because it is implemented using simple thresholding. But there are few
drawbacks of ReLU neuron :

Not zero-centered: The outputs are not zero centered similar to the
sigmoid activation function. The other issue with ReLU is that if x
\textless{} 0 during the forward pass, the neuron remains inactive and
it kills the gradient during the backward pass. Thus weights do not get
updated, and the network does not learn. When x = 0 the slope is
undefined at that point, but this problem is taken care of during
implementation by picking either the left or the right gradient.

\textbf{Leaky ReLU}

his was an attempt to mitigate the dying ReLU problem. The function
computes

\begin{verbatim}
\[ f(x) = max(0.1x, x) \]
\end{verbatim}

The concept of leaky ReLU is when x \textless{} 0, it will have a small
positive slope of 0.1. This function somewhat eliminates the dying ReLU
problem, but the results achieved with it are not consistent. Though it
has all the characteristics of a ReLU activation function, i.e.,
computationally efficient, converges much faster, does not saturate in
positive region.

The idea of leaky ReLU can be extended even further. Instead of
multiplying x with a constant term we can multiply it with a
hyperparameter which seems to work better the leaky ReLU. This extension
to leaky ReLU is known as Parametric ReLU.

\textbf{Parametric ReLU}

The PReLU function is given by

\begin{verbatim}
\[ f(x) = \max(\alpha x, x) \]
\end{verbatim}

Where \alpha is a hyperparameter. The idea here was to introduce an
arbitrary hyperparameter \alpha, and this \alpha can be learned since
you can backpropagate into it. This gives the neurons the ability to
choose what slope is best in the negative region, and with this ability,
they can become a ReLU or a leaky ReLU.

In summary, it is better to use ReLU, but you can experiment with Leaky
ReLU or Parametric ReLU to see if they give better results for your
problem

\textbf{SWISH}

Also known as a self-gated activation function, has recently been
released by researchers at Google. Mathematically it is represented as

\begin{verbatim}
\[ \sigma(x) = \frac{x}{1 + e^{-x}} \]
\end{verbatim}

According to the paper, the SWISH activation function performs better
than ReLU

In the negative region of the x-axis the shape of the tail is different
from the ReLU activation function and because of this the output from
the Swish activation function may decrease even when the input value
increases. Most activation functions are monotonic, i.e., their value
never decreases as the input increases. Swish has one-sided boundedness
property at zero, it is smooth and is non-monotonic. It will be
interesting to see how well it performs by changing just one line of
code.

https://www.learnopencv.com/understanding-activation-functions-in-deep-learning/

\textbf{Softmax}

The softmax function is also a type of sigmoid function but is handy
when we are trying to handle classification problems. The sigmoid
function as we saw earlier was able to handle just two classes. What
shall we do when we are trying to handle multiple classes. Just
classifying yes or no for a single class would not help then. The
softmax function would squeeze the outputs for each class between 0 and
1 and would also divide by the sum of the outputs. (convertir los
valores en probabilidad)

\hypertarget{choosing-the-right-activation-function}{%
\subsection{Choosing the right Activation
Function}\label{choosing-the-right-activation-function}}

\begin{itemize}
\tightlist
\item
  Sigmoid functions and their combinations generally work better in the
  case of classifiers
\item
  Sigmoids and tanh functions are sometimes avoided due to the vanishing
  gradient problem
\item
  ReLU function is a general activation function and is used in most
  cases these days
\item
  If we encounter a case of dead neurons in our networks the leaky ReLU
  function is the best choice
\item
  Always keep in mind that ReLU function should only be used in the
  hidden layers
\item
  As a rule of thumb, you can begin with using ReLU function and then
  move over to other activation functions in case ReLU doesn't provide
  with optimum results
\end{itemize}

    \hypertarget{loss-functions}{%
\paragraph{Loss functions}\label{loss-functions}}

Take care of the \textbf{objective function} (loss function). Choosing
the right objective function for the right problem is extremely
important: your network will take any shortcut it can, to minimize the
loss; so if the objective doesn't fully correlate with success for the
task at hand, your network will end up doing things you may not have
wanted.

Fortunately, when it comes to common problems such as classification,
regression, and sequence prediction, there are simple guidelines you can
follow to choose the correct loss. For instance, * you'll use
\textbf{binary crossentropy} for a two-class classification problem, *
\textbf{categorical crossentropy} for a many-class classification
problem, * \textbf{mean-squared error} for a regression problem, *
\textbf{connectionist temporal classification (CTC)} for a
sequence-learning problem, and so on.

Only when you're working on truly new research problems will you have to
develop your own objective functions.

\hypertarget{bag-of-words-vs.embbedings}{%
\paragraph{Bag of words
vs.~Embbedings}\label{bag-of-words-vs.embbedings}}

https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a

\hypertarget{data-augmentation}{%
\paragraph{Data Augmentation}\label{data-augmentation}}

Deep learning algorithms often perform better with more data. If you
can't reasonably get more data, you can invent more data.

\begin{itemize}
\tightlist
\item
  If your data are vectors of numbers, create randomly modified versions
  of existing vectors.
\item
  If your data are images, create randomly modified versions of existing
  images.
\item
  If your data are text, you get the idea\ldots{}
\end{itemize}

Often this is called \textbf{data augmentation or data generation.} You
can use a generative model. You can also use simple tricks. \textbf{For
example:} * with photograph image data, you can get big gains by
randomly shifting and rotating existing images. It improves the
generalization of the model to such transforms in the data if they are
to be expected in new data. * remenber the problem of optimal price for
insurance

\textbf{ImageDataGenerator }

Keras provides the ImageDataGenerator class that defines the
configuration for image data preparation and augmentation. This includes
capabilities such as:

\begin{itemize}
\tightlist
\item
  Sample-wise standardization.
\item
  Feature-wise standardization.
\item
  ZCA whitening.
\item
  Random rotation, shifts, shear and flips.
\item
  Dimension reordering.
\item
  Save augmented images to disk.
\item
  An augmented image generator can be created as follows:
\end{itemize}

\texttt{datagen\ =\ ImageDataGenerator()}

Rather than performing the operations on your entire image dataset in
memory, the API is designed to be iterated by the deep learning model
fitting process, creating augmented image data for you just-in-time.
This reduces your memory overhead, but adds some additional time cost
during model training.

https://machinelearningmastery.com/image-augmentation-deep-learning-keras/

\hypertarget{tips}{%
\subparagraph{TIPS}\label{tips}}

\begin{itemize}
\item
  Avoid bottlenecks, the hidden nodes have to be grater in number in
  comparison with the input nodes.
\item
  Take in consideration the rate of learning and momentum.
\item
  The neural networks consedire interactions between variables (for this
  reason more nodes are more interactions). Te problem is the
  interpretability because you never know which variables and which
  interactions are the better.
\item
  Data augmentaton to fit overfittithg. Sometime the overfitting is
  because you do not show to the machine all the patters so, you have to
  create more data in order to have more information.
\item
  \textbf{Rescale Your Data} to the bounds of your activation functions.
  If you are using sigmoid activation functions, rescale your data to
  values between 0-and-1. If you're using the Hyperbolic Tangent (tanh),
  rescale to values between -1 and 1. This applies to inputs (x) and
  outputs (y). For example, if you have a sigmoid on the output layer to
  predict binary values, normalize your y values to be binary. If you
  are using softmax, you can still get benefit from normalizing your y
  values. I would suggest that you create a few different versions of
  your training dataset as follows:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Normalized to 0 to 1.
\item
  Rescaled to -1 to 1.
\item
  Standardized.
\end{enumerate}

Then evaluate the performance of your model on each. Pick one, then
double down. If you change your activation functions, repeat this little
experiment. Big values accumulating in your network are not good. In
addition, there are other methods for keeping numbers small in your
network such as normalizing activation and weights, but we'll look at
these techniques later.

\begin{itemize}
\tightlist
\item
  \textbf{Transform Your Data}
\end{itemize}

Related to rescaling suggested above, but more work. You must really get
to know your data. Visualize it. Look for outliers. Guesstimate the
univariate distribution of each column.

\begin{itemize}
\tightlist
\item
  Does a column look like a skewed Gaussian, consider adjusting the skew
  with a Box-Cox transform.
\item
  Does a column look like an exponential distribution, consider a log
  transform.
\item
  Does a column look like it has some features, but they are being
  clobbered by something obvious, try squaring, or square-rooting.
\item
  Can you make a feature discrete or binned in some way to better
  emphasize some feature.
\end{itemize}

Lean on your intuition. Try things.

\begin{itemize}
\tightlist
\item
  Can you pre-process data with a projection method like PCA?
\item
  Can you aggregate multiple attributes into a single value?
\item
  Can you expose some interesting aspect of the problem with a new
  boolean flag?
\item
  Can you explore temporal or other structure in some other way?
\item
  Neural nets perform feature learning. They can do this stuff.
\end{itemize}

But they will also learn a problem much faster if you can better expose
the structure of the problem to the network for learning. Spot-check
lots of different transforms of your data or of specific attributes and
see what works and what doesn't.

\textbf{Code to scale data}
https://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/

\textbf{Other tips}
https://machinelearningmastery.com/improve-deep-learning-performance/

\hypertarget{hyperarameter-optimization}{%
\paragraph{Hyperarameter
optimization}\label{hyperarameter-optimization}}

https://towardsdatascience.com/hyperparameter-optimization-with-keras-b82e6364ca53

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{c+c1}{\PYZsh{} Load libraries}
        
        \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{import} \PY{n+nn}{sys}
        
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Activation}\PY{p}{,} \PY{n}{Dense}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
        \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{}kernel\PYZus{}initializer (initializations of weights)}
        \PY{c+c1}{\PYZsh{}kernel\PYZus{}initializer : random\PYZus{}uniform/uniform, random\PYZus{}normal, zero}
        
        \PY{c+c1}{\PYZsh{}It means 8 input parameters, with 12 neurons in the FIRST hidden layer.}
        \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{random\PYZus{}uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using TensorFlow backend.

    \end{Verbatim}

    \hypertarget{help}{%
\subsection{HELP}\label{help}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{n}{help}\PY{p}{(}\PY{n+nb}{len}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Help on built-in function len in module builtins:

len(obj, /)
    Return the number of items in a container.


    \end{Verbatim}

    \hypertarget{keras}{%
\subsection{KERAS}\label{keras}}

Keras is a deep-learning framework for Python that provides a convenient
way to define and train almost any kind of deep-learning model. Keras
was initially developed for researchers, with the aim of enabling fast
experimentation.

Keras has the following key features: * It allows the same code to run
seamlessly on CPU or GPU . * It has a user-friendly API that makes it
easy to quickly prototype deep-learning models. * It has built-in
support for convolutional networks (for computer vision), recur- rent
networks (for sequence processing), and any combination of both. * It
supports arbitrary network architectures: multi-input or multi-output
models, layer sharing, model sharing, and so on. This means Keras is
appropriate for building essentially any deep-learning model, from a
generative adversarial net- work to a neural Turing machine

Keras has well over 200,000 users, ranging from academic researchers and
engi- neers at both startups and large companies to graduate students
and hobbyists. Keras is used at Google, Netflix, Uber, CERN , Yelp,
Square, and hundreds of startups work- ing on a wide range of problems.
Keras is also a popular framework on Kaggle, the machine-learning
competition website, where almost every recent deep-learning com-
petition has been won using Keras models

Keras can be run with any of the backends: tHEANO, CNK \& TENSORFLOW

    \hypertarget{mnist}{%
\subsection{MNIST}\label{mnist}}

MNIST es un conjunto de 60000 imágenes de dígitos manuscritos
recopilados por el National Institute of Standards and Technology (NIST)
en los años 80. Se ha convertido en un conjunto de datos básico para
comprobar el funcionamiento de cualquier algoritmo de Deep Learning.
Esta base de datos también contiene 10000 imágenes para realizar los
tests una vez entrenada la red neuronal. En este ejemplo veremos como
construir una FFNN para resolver este problema usando la librería Keras.

\begin{itemize}
\tightlist
\item
  Separar los datos en conjuntos de entrenamiento y de comprobación o
  test.
\item
  Escalar los datos y convertirlos en matrices o conjuntos de
  categorías.
\item
  Diseñar la red neuronal eligiendo el número y tipo de capas y los
  filtros.
\item
  Entrenar la red con ``fit''.
\item
  Validar el modelo con el conjunto de datos reservado como test.
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k}{import} \PY{n}{mnist}
        \PY{p}{(}\PY{n}{train\PYZus{}images}\PY{p}{,} \PY{n}{train\PYZus{}labels}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{test\PYZus{}images}\PY{p}{,} \PY{n}{test\PYZus{}labels}\PY{p}{)} \PY{o}{=} \PY{n}{mnist}\PY{o}{.}\PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{train\PYZus{}images}\PY{o}{.}\PY{n}{shape}
        
        \PY{p}{(}\PY{n}{train\PYZus{}images}\PY{p}{,} \PY{n}{train\PYZus{}labels}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{test\PYZus{}images}\PY{p}{,} \PY{n}{test\PYZus{}labels}\PY{p}{)} \PY{o}{=} \PY{n}{mnist}\PY{o}{.}\PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \hypertarget{tensors}{%
\subsection{TENSORS}\label{tensors}}

Tha data is defined as a multidimensional Numpy arrays, also called
\textbf{tensors}.

In general, all current machine-learning systems use tensors as their
basic data structure. Tensors are fundamental to the field---so
fundamental that Google's TensorFlow was named after them. So what's a
tensor? At its core, a tensor is a container for data---almost always
numerical data. So, it's a container for numbers. You may be already
familiar with matrices, which are 2D ten- sors: tensors are a
generalization of matrices to an arbitrary number of dimensions (note
that in the context of tensors, a dimension is often called an axis)

\textbf{Scalars (0D tensors)}

A tensor that contains only one number is called a scalar (or scalar
tensor, or 0-dimensional tensor, or 0D tensor). In Numpy, a float32 or
float64 number is a scalar tensor (or scalar array). You can display the
number of axes of a Numpy tensor via the ndim attribute; a sca- lar
tensor has 0 axes ( ndim == 0 ). The number of axes of a tensor is also
called its rank.

\textbf{Vectors (1D tensors)}

An array of numbers is called a vector, or 1D tensor. A 1D tensor is
said to have exactly one axis. This vector has five entries and so is
called a 5-dimensional vector. Don't confuse a 5D vector with a 5D
tensor! A 5D vector has only one axis and has five dimensions along its
axis, whereas a 5D tensor has five axes (and may have any number of
dimensions along each axis).

\textbf{Matrices (2D tensors)}

An array of vectors is a matrix, or 2D tensor. A matrix has two axes
(often referred to rows and columns).

\textbf{3D tensors and higher-dimensional tensors}

If you pack such matrices in a new array, you obtain a 3D tensor, which
you can visually interpret as a cube of numbers.

By packing 3D tensors in an array, you can create a 4D tensor, and so
on. In deep learn- ing, you'll generally manipulate tensors that are 0D
to 4D , although you may go up to 5D if you process video data.

\hypertarget{key-attributes}{%
\subsection{Key attributes}\label{key-attributes}}

A tensor is defined by three key attributes: * Number of axes
(rank)---For instance, a 3D tensor has three axes, and a matrix has two
axes. This is also called the tensor's ndim in Python libraries such as
Numpy. * Shape---This is a tuple of integers that describes how many
dimensions the ten- sor has along each axis. For instance, the previous
matrix example has shape (3, 5) , and the 3D tensor example has shape
(3, 3, 5) . A vector has a shape with a single element, such as (5,) ,
whereas a scalar has an empty shape, () . * Data type (usually called
dtype in Python libraries)---This is the type of the data contained in
the tensor; for instance, a tensor's type could be float32 , uint8 ,
float64 , and so on. On rare occasions, you may see a char tensor. Note
that string tensors don't exist in Numpy (or in most other libraries),
because tensors live in preallocated, contiguous memory segments: and
strings, being variable length, would preclude the use of this
implementation.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{train\PYZus{}images}\PY{o}{.}\PY{n}{ndim}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{train\PYZus{}images}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{train\PYZus{}images}\PY{o}{.}\PY{n}{dtype}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
3
(60000, 28, 28)
uint8

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{n}{i} \PY{o}{=} \PY{l+m+mi}{1}
        \PY{n}{img} \PY{o}{=} \PY{n}{train\PYZus{}images}\PY{p}{[}\PY{n}{i}\PY{p}{]}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Greys}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    
    \begin{verbatim}
<Figure size 640x480 with 1 Axes>
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{n}{i} \PY{o}{=} \PY{l+m+mi}{1}
        \PY{n}{img} \PY{o}{=} \PY{n}{train\PYZus{}images}\PY{p}{[}\PY{n}{i}\PY{p}{]}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{img}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_12_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{training-a-net}{%
\subsection{TRAINING A NET}\label{training-a-net}}

\begin{itemize}
\item
  The core building block of neural networks is the layer, a
  data-processing module that you can think of as a filter for data.
  Some data goes in, and it comes out in a more use- ful form.
  Specifically, layers extract representations out of the data fed into
  them---hope- fully, representations that are more meaningful for the
  problem at hand. Most of deep learning consists of chaining together
  simple layers that will implement a form of progressive data
  distillation. A deep-learning model is like a sieve for data process-
  ing, made of a succession of increasingly refined data filters---the
  layers.
\item
  Here, our network consists of a sequence of two Dense layers, which
  are densely connected (also called fully connected) neural layers. The
  second (and last) layer is a 10-way softmax layer, which means it will
  return an array of 10 probability scores (sum- ming to 1). Each score
  will be the probability that the current digit image belongs to one of
  our 10 digit classes.
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{k+kn}{from} \PY{n+nn}{keras} \PY{k}{import} \PY{n}{models}
        \PY{k+kn}{from} \PY{n+nn}{keras} \PY{k}{import} \PY{n}{layers}
        \PY{n}{network} \PY{o}{=} \PY{n}{models}\PY{o}{.}\PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
        \PY{n}{network}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{layers}\PY{o}{.}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{512}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{28} \PY{o}{*} \PY{l+m+mi}{28}\PY{p}{,}\PY{p}{)}\PY{p}{)}\PY{p}{)}
        \PY{n}{network}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{layers}\PY{o}{.}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    To make the network ready for training, we need to pick three more
things, as part of the compilation step: * \textbf{A loss
function}---How the network will be able to measure its performance on
the training data, and thus how it will be able to steer itself in the
right direc- tion. * \textbf{An optimizer}---The mechanism through which
the network will update itself based on the data it sees and its loss
function. * \textbf{Metrics to monitor during training and testing}
---Here, we'll only care about accu- racy (the fraction of the images
that were correctly classified).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{}Compilation step}
        \PY{n}{network}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{optimizer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rmsprop}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    Before training, we'll preprocess the data by reshaping it into the
shape the network expects and scaling it so that all values are in the
{[}0, 1{]} interval. Previously, our train- ing images, for instance,
were stored in an array of shape (60000, 28, 28) of type uint8 with
values in the {[}0, 255{]} interval. We transform it into a float32
array of shape (60000, 28 * 28) with values between 0 and 1.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{n}{train\PYZus{}images} \PY{o}{=} \PY{n}{train\PYZus{}images}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{60000}\PY{p}{,} \PY{l+m+mi}{28} \PY{o}{*} \PY{l+m+mi}{28}\PY{p}{)}\PY{p}{)}
        \PY{n}{train\PYZus{}images} \PY{o}{=} \PY{n}{train\PYZus{}images}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{float32}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o}{/} \PY{l+m+mi}{255}
        \PY{n}{test\PYZus{}images} \PY{o}{=} \PY{n}{test\PYZus{}images}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{10000}\PY{p}{,} \PY{l+m+mi}{28} \PY{o}{*} \PY{l+m+mi}{28}\PY{p}{)}\PY{p}{)}
        \PY{n}{test\PYZus{}images} \PY{o}{=} \PY{n}{test\PYZus{}images}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{float32}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o}{/} \PY{l+m+mi}{255}
\end{Verbatim}


    We also need to categorically encode the labels

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{to\PYZus{}categorical}
         \PY{n}{train\PYZus{}labels} \PY{o}{=} \PY{n}{to\PYZus{}categorical}\PY{p}{(}\PY{n}{train\PYZus{}labels}\PY{p}{)}
         \PY{n}{test\PYZus{}labels} \PY{o}{=} \PY{n}{to\PYZus{}categorical}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{)}
\end{Verbatim}


    We're now ready to train the network, which in Keras is done via a call
to the network's fit method---we fit the model to its training data.

Here, he network will start to iterate on the training data in
mini-batches of 128 samples, 5 times over (each iteration over all the
training data is called an epoch). At each iteration, the network will
compute the gradients of the weights with regard to the loss on the
batch, and update the weights

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{n}{network}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train\PYZus{}images}\PY{p}{,} \PY{n}{train\PYZus{}labels}\PY{p}{,} \PY{n}{epochs}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{128}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Epoch 1/5
60000/60000 [==============================] - 19s 315us/step - loss: 0.2594 - acc: 0.9250
Epoch 2/5
60000/60000 [==============================] - 12s 203us/step - loss: 0.1053 - acc: 0.9689
Epoch 3/5
60000/60000 [==============================] - 12s 205us/step - loss: 0.0691 - acc: 0.9795
Epoch 4/5
60000/60000 [==============================] - 13s 212us/step - loss: 0.0508 - acc: 0.9844
Epoch 5/5
60000/60000 [==============================] - 12s 202us/step - loss: 0.0381 - acc: 0.9885

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}11}]:} <keras.callbacks.History at 0x7fc02421af28>
\end{Verbatim}
            
    We quickly reach an accuracy of 0.989 (98.9\%) on the training data. Now
let's check that the model performs well on the test set, too:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{n}{test\PYZus{}loss}\PY{p}{,} \PY{n}{test\PYZus{}acc} \PY{o}{=} \PY{n}{network}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{test\PYZus{}images}\PY{p}{,} \PY{n}{test\PYZus{}labels}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}acc:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{test\PYZus{}acc}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
10000/10000 [==============================] - 2s 206us/step
test\_acc: 0.9805

    \end{Verbatim}

    The test-set accuracy turns out to be 97.8\%---that's quite a bit lower
than the training set accuracy. This gap between training accuracy and
test accuracy is an example of overfitting: the fact that
machine-learning models tend to perform worse on new data than on their
training data.

    \hypertarget{manipulating-tensors-in-numpy}{%
\subsection{MANIPULATING TENSORS IN
NUMPY}\label{manipulating-tensors-in-numpy}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{c+c1}{\PYZsh{} equivalents}
         \PY{n}{my\PYZus{}slice} \PY{o}{=} \PY{n}{train\PYZus{}images}\PY{p}{[}\PY{l+m+mi}{10}\PY{p}{:}\PY{l+m+mi}{100}\PY{p}{]}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{my\PYZus{}slice}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{c+c1}{\PYZsh{}my\PYZus{}slice = train\PYZus{}images[10:100, :, :]}
         \PY{c+c1}{\PYZsh{}print(my\PYZus{}slice.shape)}
         \PY{c+c1}{\PYZsh{}my\PYZus{}slice = train\PYZus{}images[10:100, 0:28, 0:28]}
         \PY{c+c1}{\PYZsh{}print(my\PYZus{}slice.shape)}
         
         \PY{c+c1}{\PYZsh{}my\PYZus{}slice = train\PYZus{}images[:, 14:, 14:]}
         \PY{c+c1}{\PYZsh{}print(my\PYZus{}slice.shape)}
         \PY{c+c1}{\PYZsh{}my\PYZus{}slice = train\PYZus{}images[:, 7:\PYZhy{}7, 7:\PYZhy{}7]}
         \PY{c+c1}{\PYZsh{}print(my\PYZus{}slice.shape)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(90, 784)

    \end{Verbatim}

    \hypertarget{the-notion-of-data-batches}{%
\subsection{The notion of data
batches}\label{the-notion-of-data-batches}}

    Deep-learning models don't process an entire dataset at once; rather,
they break the data into small batches. Concretely, here's one batch of
our MNIST digits, with batch size of 128:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{n}{batch} \PY{o}{=} \PY{n}{train\PYZus{}images}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{128}\PY{p}{]}
         \PY{c+c1}{\PYZsh{}And here’s the next batch:}
         \PY{n}{batch} \PY{o}{=} \PY{n}{train\PYZus{}images}\PY{p}{[}\PY{l+m+mi}{128}\PY{p}{:}\PY{l+m+mi}{256}\PY{p}{]}
         \PY{c+c1}{\PYZsh{}And the n th batch:}
         \PY{n}{n} \PY{o}{=}\PY{l+m+mi}{1}
         \PY{n}{batch} \PY{o}{=} \PY{n}{train\PYZus{}images}\PY{p}{[}\PY{l+m+mi}{128} \PY{o}{*} \PY{n}{n}\PY{p}{:}\PY{l+m+mi}{128} \PY{o}{*} \PY{p}{(}\PY{n}{n} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}
\end{Verbatim}


    \hypertarget{real-world-examples-of-data-tensors}{%
\subsection{Real-world examples of data
tensors}\label{real-world-examples-of-data-tensors}}

Let's make data tensors more concrete with a few examples similar to
what you'll encounter later. The data you'll manipulate will almost
always fall into one of the fol- lowing categories: * Vector data--- 2D
tensors of shape (samples, features) * Timeseries data or sequence
data--- 3D tensors of shape (samples, timesteps, features) * Images---
4D tensors of shape (samples, height, width, channels) or (samples,
channels, height, width) * Video--- 5D tensors of shape (samples,
frames, height, width, channels) or (samples, frames, channels, height,
width)

\hypertarget{image-data}{%
\subsection{Image data}\label{image-data}}

Images typically have three dimensions: height, width, and color depth.
Although grayscale images (like our MNIST digits) have only a single
color channel and could thus be stored in 2D tensors, by convention
image tensors are always 3D , with a one- dimensional color channel for
grayscale images. A batch of 128 grayscale images of size 256 × 256
could thus be stored in a tensor of shape (128, 256, 256, 1) , and a
batch of 128 color images could be stored in a tensor of shape (128,
256, 256, 3)

    \hypertarget{tensor-reshaping}{%
\subsection{Tensor reshaping}\label{tensor-reshaping}}

A third type of tensor operation that's essential to understand is
tensor reshaping. Although it wasn't used in the Dense layers in our
first neural network example, we used it when we preprocessed the digits
data before feeding it into our network: train\_images =
train\_images.reshape((60000, 28 * 28)) Reshaping a tensor means
rearranging its rows and columns to match a target shape. Naturally, the
reshaped tensor has the same total number of coefficients as the initial
tensor. Reshaping is best understood via simple examples:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{1.}\PY{p}{]}\PY{p}{,}
         \PY{p}{[}\PY{l+m+mf}{2.}\PY{p}{,} \PY{l+m+mf}{3.}\PY{p}{]}\PY{p}{,}
         \PY{p}{[}\PY{l+m+mf}{4.}\PY{p}{,} \PY{l+m+mf}{5.}\PY{p}{]}\PY{p}{]}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         
         \PY{n}{x} \PY{o}{=} \PY{n}{x}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         
         \PY{n}{x} \PY{o}{=} \PY{n}{x}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        NameError                                 Traceback (most recent call last)

        <ipython-input-15-8452973d4105> in <module>()
    ----> 1 x = np.array([[0., 1.],
          2 [2., 3.],
          3 [4., 5.]])
          4 print(x.shape)
          5 


        NameError: name 'np' is not defined

    \end{Verbatim}

    A special case of reshaping that's commonly encountered is
transposition. Transposing a matrix means exchanging its rows and its
columns, so that x{[}i, :{]} becomes x{[}:, i{]} :

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{300}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{n}{x}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \hypertarget{developing-with-keras-a-quick-overview}{%
\subsection{Developing with Keras: a quick
overview}\label{developing-with-keras-a-quick-overview}}

You've already seen one example of a Keras model: the MNIST example. The
typical Keras workflow looks just like that example:

\begin{itemize}
\tightlist
\item
  Define your training data: input tensors and target tensors.
\item
  Define a network of layers (or model ) that maps your inputs to your
  targets.
\item
  Configure the learning process by choosing a loss function, an
  optimizer, and some metrics to monitor.
\item
  Iterate on your training data by calling the fit() method of your
  model.
\end{itemize}

There are two ways to define a model: using the \textbf{Sequential
class} (only for linear stacks of layers, which is the most common
network architecture by far) or the \textbf{func- tional API} (for
directed acyclic graphs of layers, which lets you build completely arbi-
trary architectures).

Once your model architecture is defined, it doesn't matter whether you
used a Sequential model or the functional API . All of the following
steps are the same.

Finally, the learning process consists of passing Numpy arrays of input
data (and the corresponding target data) to the model via the fit()
method, similar to what you would do in Scikit-Learn and several other
machine-learning libraries:

\texttt{model.fit(input\_tensor,\ target\_tensor,\ batch\_size=128,\ epochs=10)}

\hypertarget{objective-function}{%
\subsection{OBJECTIVE FUNCTION}\label{objective-function}}

Take care of the \textbf{objective function} (loss function). Choosing
the right objective function for the right problem is extremely
important: your network will take any shortcut it can, to minimize the
loss; so if the objective doesn't fully correlate with success for the
task at hand, your network will end up doing things you may not have
wanted.

Fortunately, when it comes to common problems such as classification,
regression, and sequence prediction, there are simple guidelines you can
follow to choose the correct loss. For instance, * you'll use
\textbf{binary crossentropy} for a two-class classification problem, *
\textbf{categorical crossentropy} for a many-class classification
problem, * \textbf{mean-squared error} for a regression problem, *
\textbf{connectionist temporal classification (CTC)} for a
sequence-learning problem, and so on.

Only when you're working on truly new research problems will you have to
develop your own objective functions.

    \hypertarget{gpu}{%
\subsection{GPU}\label{gpu}}

it's highly recommended, although not strictly necessary, that you run
deep-learning code on a modern NVIDIA GPU

If you don't want to install a GPU on your machine, you can
alternatively consider running your experi- ments on an \textbf{AWS EC2
GPU} instance or on Google Cloud Platform. But note that cloud GPU
instances can become expensive over time

    Use the official \textbf{EC2 Deep Learning AMI}
(https://aws.amazon.com/amazon- ai/amis), and run Keras experiments as
Jupyter notebooks on EC2 . Do this if you don't already have a GPU on
your local machine.

    \hypertarget{the-imdb-dataset}{%
\subsection{The IMDB dataset}\label{the-imdb-dataset}}

    \begin{itemize}
\item
  A set of 50,000 highly polarized reviews from the Internet Movie
  Database. They're split into 25,000 reviews for training and 25,000
  reviews for testing, each set consisting of 50\% negative and 50\%
  positive reviews.
\item
  The reviews (sequences of words) have been turned into sequences of
  integers, where each integer stands for a specific word in a
  dictionary.
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k}{import} \PY{n}{imdb}
        \PY{n}{help}\PY{p}{(}\PY{n}{imdb}\PY{o}{.}\PY{n}{load\PYZus{}data}\PY{p}{)} \PY{c+c1}{\PYZsh{} this load the numeric data. We prefer to see the process since the beggining}
\end{Verbatim}


    The function above, load the numeric data. We prefer to see the process
since the beggining

    \textbf{Loading the IMDB dataset}

The dataset is available at
https://www.kaggle.com/c/word2vec-nlp-tutorial/data

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{n}{imdb\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{IMBD/labeledTrainData.tsv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{sep} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} reproducibility}
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{42}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{pd}\PY{o}{.}\PY{n}{set\PYZus{}option}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{display.max\PYZus{}colwidth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{500}\PY{p}{)}
        \PY{n}{imdb\PYZus{}df}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


    \hypertarget{data-tokenization}{%
\subsection{Data Tokenization}\label{data-tokenization}}

The text data need to be converted into vectors using either \textbf{bag
of words or embeddings model}. We will first explore bag of words (BOW)
model. In the BOW model, a sentence will be represented as a vector with
the words (also called tokens) as dimensions of the vectors.

For the purpose of creating vectors, we need to tokenize the sentences
first and find out all unique tokens (words) used across all sentences.
The corpus of unquie words used could very large, so we can limit the
corpus of tokens by using only the most popular (frequently used) words.
In this example, we will use 10000 words.

\hypertarget{tokenizer}{%
\subsection{TOKENIZER}\label{tokenizer}}

Tokenizer provides 4 attributes that you can use to query what has been
learned about your documents:

\begin{itemize}
\tightlist
\item
  word\_counts: A dictionary of words and their counts.
\item
  word\_docs: A dictionary of words and how many documents each appeared
  in.
\item
  word\_index: A dictionary of words and their uniquely assigned
  integers.
\item
  document\_count:An integer count of the total number of documents that
  were used to fit the Tokenizer.
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{preprocessing}\PY{n+nn}{.}\PY{n+nn}{text} \PY{k}{import} \PY{n}{Tokenizer}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{all\PYZus{}tokenizer} \PY{o}{=} \PY{n}{Tokenizer}\PY{p}{(}\PY{p}{)}
        \PY{n}{all\PYZus{}tokenizer} 
        \PY{n}{all\PYZus{}tokenizer}\PY{o}{.}\PY{n}{fit\PYZus{}on\PYZus{}texts}\PY{p}{(} \PY{n}{imdb\PYZus{}df}\PY{o}{.}\PY{n}{review} \PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n+nb}{type}\PY{p}{(}\PY{n}{all\PYZus{}tokenizer}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{all\PYZus{}tokenizer}\PY{o}{.}\PY{n}{document\PYZus{}count}
\end{Verbatim}

There are 25000 documents (reviews) and 88582 unique words.
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n+nb}{len}\PY{p}{(}\PY{n}{all\PYZus{}tokenizer}\PY{o}{.}\PY{n}{word\PYZus{}counts}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}high frequency words}
        \PY{n+nb}{list}\PY{p}{(}\PY{n}{all\PYZus{}tokenizer}\PY{o}{.}\PY{n}{word\PYZus{}counts}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{10}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}low frequency words}
        \PY{n+nb}{list}\PY{p}{(}\PY{n}{all\PYZus{}tokenizer}\PY{o}{.}\PY{n}{word\PYZus{}counts}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{10}\PY{p}{:}\PY{p}{]}
\end{Verbatim}


    We can assume the low frequencey words are rarely used to express
sentiments as they have appeared only once across all reviews. And only
choose to keep top N (for example 10000) words for our analysis. So,
let's tokenize agains with a limit to number of words to 10000.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{num\PYZus{}words} \PY{o}{=} \PY{l+m+mi}{10000}
        \PY{n}{tokenizer} \PY{o}{=} \PY{n}{Tokenizer}\PY{p}{(}\PY{n}{num\PYZus{}words} \PY{o}{=} \PY{n}{num\PYZus{}words}\PY{p}{)}
        \PY{n}{tokenizer}\PY{o}{.}\PY{n}{fit\PYZus{}on\PYZus{}texts}\PY{p}{(} \PY{n}{imdb\PYZus{}df}\PY{o}{.}\PY{n}{review} \PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}Checking first few words and their counts}
        \PY{k+kn}{import} \PY{n+nn}{itertools}
        
        \PY{n}{x} \PY{o}{=} \PY{n}{itertools}\PY{o}{.}\PY{n}{islice}\PY{p}{(}\PY{n}{tokenizer}\PY{o}{.}\PY{n}{word\PYZus{}counts}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}
        
        \PY{k}{for} \PY{n}{key}\PY{p}{,} \PY{n}{value} \PY{o+ow}{in} \PY{n}{x}\PY{p}{:}
            \PY{n+nb}{print}\PY{p}{(}\PY{n}{key}\PY{p}{,} \PY{n}{value}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}Checking words and their indexes}
        \PY{n+nb}{list}\PY{p}{(}\PY{n}{tokenizer}\PY{o}{.}\PY{n}{word\PYZus{}index}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{10}\PY{p}{:}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n+nb}{list}\PY{p}{(}\PY{n}{tokenizer}\PY{o}{.}\PY{n}{word\PYZus{}index}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{l+m+mi}{10}\PY{p}{]}
\end{Verbatim}


    \hypertarget{encoding}{%
\subsection{Encoding}\label{encoding}}

\begin{itemize}
\tightlist
\item
  Encoding a text using the dictionary of tokens
\item
  Finding indexes of the words
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{OrderedDict}
        \PY{n}{words\PYZus{}by\PYZus{}sorted\PYZus{}index} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{tokenizer}\PY{o}{.}\PY{n}{word\PYZus{}index}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{,} 
                                                   \PY{n}{key}\PY{o}{=}\PY{k}{lambda} \PY{n}{idx}\PY{p}{:} \PY{n}{idx}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
        \PY{n+nb}{type}\PY{p}{(}\PY{n}{words\PYZus{}by\PYZus{}sorted\PYZus{}index}\PY{p}{)}
        \PY{n}{words\PYZus{}by\PYZus{}sorted\PYZus{}index}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{10}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{tokenizer}\PY{o}{.}\PY{n}{word\PYZus{}index}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{the}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{tokenizer}\PY{o}{.}\PY{n}{word\PYZus{}index}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{a}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{tokenizer}\PY{o}{.}\PY{n}{texts\PYZus{}to\PYZus{}sequences}\PY{p}{(} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{The movie gladiator is a brilliant movie}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \hypertarget{encoding-all-the-movie-reviews}{%
\subsection{Encoding all the movie
reviews}\label{encoding-all-the-movie-reviews}}

Now the documents (reviews) will be encoded as per the dictionary.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{time}
        sequences = tokenizer.texts\PYZus{}to\PYZus{}sequences(imdb\PYZus{}df.review)
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}Let\PYZsq{}s look at the words index sequences for a specific sentence.}
        \PY{n}{imdb\PYZus{}df}\PY{o}{.}\PY{n}{review}\PY{p}{[}\PY{l+m+mi}{10}\PY{p}{:}\PY{l+m+mi}{11}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{sequences}\PY{p}{[}\PY{l+m+mi}{10}\PY{p}{:}\PY{l+m+mi}{11}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \hypertarget{encode-y-variable}{%
\subsection{Encode Y Variable}\label{encode-y-variable}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{imdb\PYZus{}df}\PY{o}{.}\PY{n}{sentiment}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{y}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{5}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}How many classes available?}
        \PY{n}{imdb\PYZus{}df}\PY{o}{.}\PY{n}{sentiment}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \hypertarget{truncate-and-pad-sequences}{%
\subsection{Truncate and Pad
Sequences}\label{truncate-and-pad-sequences}}

One of the problem in dealing with sentences are they are not of same
size. Some sentences will have more words and some will have fewer
words. Neural networks take input of same lenghts for training a batch.

So, we need to choose a length or size of input. Larger sentences will
have to be truncated and smaller ones need to be padded. But what size
or lenght to consider?

We need to take the length which can cover most of the sentences. Only
few need to be truncated or padded. For that we will look at the
distribution of the word or token lengths.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{num\PYZus{}tokens} \PY{o}{=} \PY{p}{[}\PY{n+nb}{len}\PY{p}{(}\PY{n}{tokens}\PY{p}{)} \PY{k}{for} \PY{n}{tokens} \PY{o+ow}{in} \PY{n}{sequences}\PY{p}{]}
        \PY{n}{num\PYZus{}tokens} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{num\PYZus{}tokens}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sn}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        \PY{n}{sn}\PY{o}{.}\PY{n}{distplot}\PY{p}{(} \PY{n}{num\PYZus{}tokens} \PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{mean\PYZus{}num\PYZus{}tokens} \PY{o}{=} \PY{n}{num\PYZus{}tokens}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
        \PY{n}{std\PYZus{}num\PYZus{}tokens} \PY{o}{=} \PY{n}{num\PYZus{}tokens}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{mean\PYZus{}num\PYZus{}tokens}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{std\PYZus{}num\PYZus{}tokens}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{}if we assume that legnth chosen should address 95\PYZpc{} of the sentences, then we can take 2 standard deviation }
        \PY{c+c1}{\PYZsh{}of the mean length.}
        
        \PY{n}{max\PYZus{}review\PYZus{}length} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{mean\PYZus{}num\PYZus{}tokens} \PY{o}{+} \PY{l+m+mi}{2} \PY{o}{*} \PY{n}{std\PYZus{}num\PYZus{}tokens}\PY{p}{)}
        \PY{n}{max\PYZus{}review\PYZus{}length}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}How many sentences will not be truncated at all?}
        
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{num\PYZus{}tokens} \PY{o}{\PYZlt{}} \PY{n}{max\PYZus{}review\PYZus{}length}\PY{p}{)} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{num\PYZus{}tokens}\PY{p}{)}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{}Almost 95\PYZpc{}.}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}Now we will pad or truncate. But padding or truncating can be done at the beginning of the sentence }
        \PY{c+c1}{\PYZsh{}or at the end of the sentences. pre or post can be used to specify the padding and truncating the beginning }
        \PY{c+c1}{\PYZsh{}or end of sentence.}
        
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{preprocessing}\PY{n+nn}{.}\PY{n+nn}{sequence} \PY{k}{import} \PY{n}{pad\PYZus{}sequences} 
        \PY{n}{pad} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pre}\PY{l+s+s1}{\PYZsq{}}
        \PY{n}{X} \PY{o}{=} \PY{n}{pad\PYZus{}sequences}\PY{p}{(}\PY{n}{sequences}\PY{p}{,} 
                          \PY{n}{max\PYZus{}review\PYZus{}length}\PY{p}{,} 
                          \PY{n}{padding}\PY{o}{=}\PY{n}{pad}\PY{p}{,} 
                          \PY{n}{truncating}\PY{o}{=}\PY{n}{pad}\PY{p}{)}
        \PY{n}{X}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1}\PY{p}{]}
\end{Verbatim}


    \hypertarget{split-datasets}{%
\subsection{Split Datasets}\label{split-datasets}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
        \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} 
                                                            \PY{n}{y}\PY{p}{,} 
                                                            \PY{n}{test\PYZus{}size} \PY{o}{=} \PY{l+m+mf}{0.2}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
        
        \PY{n}{input\PYZus{}shape} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


    \hypertarget{bag-of-words-model}{%
\subsection{Bag Of Words Model}\label{bag-of-words-model}}

Model Architecture

(Bag of words) -\textgreater{} Dense Layer(1024) -\textgreater{} Dense
Layer(256) -\textgreater{} Dense Layer(128) -\textgreater{} Dense
Layer(64) -\textgreater{} Relu -\textgreater{} Dense Layer(1)
-\textgreater{} Sigmoid

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{keras} \PY{k}{import} \PY{n}{backend} \PY{k}{as} \PY{n}{K}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Flatten}\PY{p}{,} \PY{n}{Dense}\PY{p}{,} \PY{n}{Activation}
        
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{42}\PY{p}{)}
        \PY{n}{K}\PY{o}{.}\PY{n}{clear\PYZus{}session}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{} clear default graph}
        
        
        \PY{n}{bow\PYZus{}model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{16}\PY{p}{,} \PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{n}{input\PYZus{}shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{p}{)}\PY{p}{)}\PY{p}{)}
        \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Activation}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
        \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{layers}\PY{o}{.}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} An \PYZdq{}activation\PYZdq{} is just a non\PYZhy{}linear function applied to the output}
        \PY{c+c1}{\PYZsh{} of the layer above. Here, with a \PYZdq{}rectified linear unit\PYZdq{},}
        \PY{c+c1}{\PYZsh{} we clamp all values below 0 to 0.}
        \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{16}\PY{p}{)}\PY{p}{)}
        \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Activation}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
        \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{layers}\PY{o}{.}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}
        \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{16}\PY{p}{)}\PY{p}{)}
        \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Activation}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
        \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{layers}\PY{o}{.}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}
        \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} This special \PYZdq{}softmax\PYZdq{} activation among other things,}
        \PY{c+c1}{\PYZsh{} ensures the output is a valid probaility distribution, that is}
        \PY{c+c1}{\PYZsh{} that its values are all non\PYZhy{}negative and sum to 1.}
        \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Activation}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
        \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{binary\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                      \PY{n}{optimizer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                      \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
        \PY{n}{EPOCHS} \PY{o}{=} \PY{l+m+mi}{15} \PY{c+c1}{\PYZsh{} INITIALLY 20, LATER YO SEE WHERE THE TRAINING AND TEST STAT TO SEPARATE A FIXED ACCORDINGLY}
        \PY{n}{BATCH\PYZus{}SIZE} \PY{o}{=} \PY{l+m+mi}{512}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{time} 
        \PYZsh{} reproducibility
        np.random.seed(42)
        \PYZsh{} fit model
        bow\PYZus{}history = bow\PYZus{}model.fit(
            X\PYZus{}train, 
            y\PYZus{}train,  \PYZsh{} prepared data
            batch\PYZus{}size = BATCH\PYZus{}SIZE,
            epochs = EPOCHS,
            shuffle = True,
            verbose=1,
            validation\PYZus{}data = (X\PYZus{}test, y\PYZus{}test)
        )
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sn}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        
        \PY{k}{def} \PY{n+nf}{plot\PYZus{}accuracy}\PY{p}{(}\PY{n}{hist}\PY{p}{)}\PY{p}{:}
            \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{hist}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{hist}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} 
                       \PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{upper left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
            
        \PY{k}{def} \PY{n+nf}{plot\PYZus{}loss}\PY{p}{(}\PY{n}{hist}\PY{p}{)}\PY{p}{:}
            \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{hist}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{hist}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} 
                       \PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{upper left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}   
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{plot\PYZus{}accuracy}\PY{p}{(} \PY{n}{bow\PYZus{}history}\PY{o}{.}\PY{n}{history} \PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{plot\PYZus{}loss}\PY{p}{(} \PY{n}{bow\PYZus{}history}\PY{o}{.}\PY{n}{history} \PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{result} \PY{o}{=} \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+si}{\PYZob{}0:.2\PYZpc{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{result}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{predict\PYZus{}classes}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{)}
        
        \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{metrics}
        \PY{n}{cm} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(} \PY{n}{y\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{,}
                                    \PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]} \PY{p}{)}
        
        \PY{n}{sn}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{cm}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}  
                   \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.2f}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                   \PY{n}{xticklabels} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Positive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Negative}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{p}{,} 
                   \PY{n}{yticklabels} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Positive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Negative}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{p}{)}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confusion Matrix for Sentiment Classification}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{classification\PYZus{}report}
        \PY{n+nb}{print}\PY{p}{(} \PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{,} 
                                     \PY{n}{y\PYZus{}pred}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \hypertarget{roc}{%
\subsection{ROC}\label{roc}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{y\PYZus{}pred\PYZus{}probs} \PY{o}{=} \PY{n}{bow\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{)}
        
        \PY{n}{auc\PYZus{}score} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(} \PY{n}{y\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{,} 
                                          \PY{n}{y\PYZus{}pred\PYZus{}probs}  \PY{p}{)}
        
        \PY{n}{fpr}\PY{p}{,} \PY{n}{tpr}\PY{p}{,} \PY{n}{thresholds} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{roc\PYZus{}curve}\PY{p}{(} \PY{n}{y\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{,}
                                                 \PY{n}{y\PYZus{}pred\PYZus{}probs}\PY{p}{,}
                                                 \PY{n}{drop\PYZus{}intermediate} \PY{o}{=} \PY{k+kc}{False} \PY{p}{)}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(} \PY{n}{fpr}\PY{p}{,} \PY{n}{tpr}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ROC curve (area = }\PY{l+s+si}{\PYZpc{}0.2f}\PY{l+s+s1}{)}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{auc\PYZus{}score} \PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{k\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlim}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{]}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.05}\PY{p}{]}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False Positive Rate or [1 \PYZhy{} True Negative Rate]}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True Positive Rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Receiver operating characteristic example}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lower right}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \hypertarget{using-embeddings-recurrent-neural-networks}{%
\subsection{Using Embeddings (Recurrent Neural
Networks)}\label{using-embeddings-recurrent-neural-networks}}

In Word embeddings, words are represented by a vector i.e.~series of
numbers (weights). The vectors represent words in a N dimension space,
in which similar meaning words are places nearer to each other while the
dissimilar words are kept far. The dimensions in the space represent
some latent factors, by which the words could be defined. All words are
assigned some weights in each each latent factors. Words that share some
common meaning have similar weights across common factors.

The word embeddings weights can be estimated during the NN model
building. There are also pre-built word embeddings are available, which
can be used in the model. We will discuss about the pre-built word
embeddings later in the tutorial.

Word embeddings are commonly used in many Natural Language Processing
(NLP) tasks because they are found to be useful representations of words
and often lead to better performance in the various tasks performed.
Given its widespread use, this post seeks to introduce the concept of
word embeddings to the prospective NLP practitioner.

Here are couple of good references to understand embeddings

https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a

(Bag of words) -\textgreater{} Embeddings (8) -\textgreater{} Dense
Layer(16) -\textgreater{} Relu -\textgreater{} Dense Layer(1)
-\textgreater{} Sigmoid

\begin{itemize}
\tightlist
\item
  We will try another optimizers and applying regularization (dropouts).
\item
  Add a dropout layer as a regularization layer for dealing with
  overfitting.
\item
  We will also add callbacks for reducing LR and early stopping. And
  store tensorflow logs for monitoring.
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{keras\PYZus{}tqdm} \PY{k}{import} \PY{n}{TQDMNotebookCallback}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{callbacks} \PY{k}{import} \PY{n}{ReduceLROnPlateau}\PY{p}{,} \PY{n}{EarlyStopping}\PY{p}{,} \PY{n}{ModelCheckpoint}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{callbacks} \PY{k}{import} \PY{n}{TensorBoard}
        
        \PY{n}{callbacks\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{n}{ReduceLROnPlateau}\PY{p}{(}\PY{n}{monitor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                            \PY{n}{factor}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} 
                                            \PY{n}{patience}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,}
                         \PY{n}{EarlyStopping}\PY{p}{(}\PY{n}{monitor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                       \PY{n}{patience}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{,}
                         \PY{n}{ModelCheckpoint}\PY{p}{(}\PY{n}{filepath}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{imdb\PYZus{}model.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                         \PY{n}{monitor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                         \PY{n}{save\PYZus{}best\PYZus{}only}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
                         \PY{n}{TensorBoard}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{./imdb\PYZus{}logs}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{,}
                         \PY{n}{TQDMNotebookCallback}\PY{p}{(}\PY{n}{leave\PYZus{}inner}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
                                              \PY{n}{leave\PYZus{}outer}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Dropout}
        
        \PY{n}{K}\PY{o}{.}\PY{n}{clear\PYZus{}session}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{emb\PYZus{}model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} We specify the maximum input length to our Embedding layer}
        \PY{c+c1}{\PYZsh{} so we can later flatten the embedded inputs}
        \PY{n}{emb\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Embedding}\PY{p}{(}\PY{l+m+mi}{10000}\PY{p}{,} 
                                  \PY{l+m+mi}{8}\PY{p}{,} 
                                  \PY{n}{input\PYZus{}length}\PY{o}{=}\PY{n}{max\PYZus{}review\PYZus{}length}\PY{p}{,}
                                  \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{layer\PYZus{}embedding}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} After the Embedding layer, }
        \PY{c+c1}{\PYZsh{} our activations have shape `(samples, maxlen, 8)`.}
        
        \PY{c+c1}{\PYZsh{} We flatten the 3D tensor of embeddings }
        \PY{c+c1}{\PYZsh{} into a 2D tensor of shape `(samples, maxlen * 8)`}
        \PY{n}{emb\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{emb\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{16}\PY{p}{)}\PY{p}{)}
        \PY{n}{emb\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Activation}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{emb\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.8}\PY{p}{)}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} We add the classifier on top}
        \PY{n}{emb\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        \PY{n}{emb\PYZus{}model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Activation}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
        \PY{n}{emb\PYZus{}model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{optimizer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{adam}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} 
                      \PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{binary\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                      \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{emb\PYZus{}history} \PY{o}{=} \PY{n}{emb\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} 
                            \PY{n}{y\PYZus{}train}\PY{p}{,}
                            \PY{n}{epochs}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,}
                            \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{,}
                            \PY{n}{callbacks} \PY{o}{=} \PY{n}{callbacks\PYZus{}list}\PY{p}{,}
                            \PY{n}{validation\PYZus{}split}\PY{o}{=}\PY{l+m+mf}{0.3}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sn}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        
        \PY{k}{def} \PY{n+nf}{plot\PYZus{}accuracy}\PY{p}{(}\PY{n}{hist}\PY{p}{)}\PY{p}{:}
            \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{hist}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{hist}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} 
                       \PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{upper left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
            
        \PY{k}{def} \PY{n+nf}{plot\PYZus{}loss}\PY{p}{(}\PY{n}{hist}\PY{p}{)}\PY{p}{:}
            \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{hist}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{hist}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} 
                       \PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{upper left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}    
        
        \PY{n}{plot\PYZus{}accuracy}\PY{p}{(} \PY{n}{emb\PYZus{}history}\PY{o}{.}\PY{n}{history} \PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{plot\PYZus{}loss}\PY{p}{(} \PY{n}{emb\PYZus{}history}\PY{o}{.}\PY{n}{history} \PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{result} \PY{o}{=} \PY{n}{emb\PYZus{}model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+si}{\PYZob{}0:.2\PYZpc{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{result}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{emb\PYZus{}model}\PY{o}{.}\PY{n}{predict\PYZus{}classes}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{)}
        
        \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{metrics}
        \PY{n}{cm} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(} \PY{n}{y\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{,}
                                    \PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]} \PY{p}{)}
        
        \PY{n}{sn}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{cm}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}  
                   \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.2f}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                   \PY{n}{xticklabels} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Positive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Negative}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{p}{,} 
                   \PY{n}{yticklabels} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Positive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Negative}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{p}{)}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confusion Matrix for Sentiment Classification}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{y\PYZus{}pred\PYZus{}probs} \PY{o}{=} \PY{n}{emb\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{)}
        
        \PY{n}{auc\PYZus{}score} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(} \PY{n}{y\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{,} 
                                          \PY{n}{y\PYZus{}pred\PYZus{}probs}  \PY{p}{)}
        
        \PY{n}{fpr}\PY{p}{,} \PY{n}{tpr}\PY{p}{,} \PY{n}{thresholds} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{roc\PYZus{}curve}\PY{p}{(} \PY{n}{y\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{,}
                                                 \PY{n}{y\PYZus{}pred\PYZus{}probs}\PY{p}{,}
                                                 \PY{n}{drop\PYZus{}intermediate} \PY{o}{=} \PY{k+kc}{False} \PY{p}{)}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(} \PY{n}{fpr}\PY{p}{,} \PY{n}{tpr}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ROC curve (area = }\PY{l+s+si}{\PYZpc{}0.2f}\PY{l+s+s1}{)}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{auc\PYZus{}score} \PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{k\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlim}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{]}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.05}\PY{p}{]}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{False Positive Rate or [1 \PYZhy{} True Negative Rate]}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True Positive Rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Receiver operating characteristic example}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lower right}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \hypertarget{tipos-de-redes}{%
\subsection{TIPOS DE REDES}\label{tipos-de-redes}}

\begin{itemize}
\item
  There are a lot of aquitectures. The following link describe some of
  then.
  https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464
\item
  The most important for us are:
\end{itemize}

\textbf{Recurrent Neural Networks} here each of hidden cell received
it's own output with fixed delay --- one or more iterations. Apart from
that, it was like common FNN.This is used when decisions from past
iterations or samples can influence current ones. The most common
examples of such contexts are texts --- a word can be analysed only in
context of previous words or sentences.

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

\textbf{Long-Short term memory (LSTM)} This type introduces a memory
cell, a special cell that can process data when data have time gaps (or
lags). \textbf{RNNs can process texts by ``keeping in mind'' ten
previous words}, and \textbf{LSTM networks can process video frame
``keeping in mind'' something that happened many frames ago}. LSTM
networks are also widely used for writing and speech recognition.

Memory cells are actually composed of a couple of elements --- called
gates, that are recurrent and control how information is being
remembered and forgotten (note that there are no activation functions
between blocks).

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

\textbf{Deep Convolutional Networks}

DCN nowadays are stars of artificial neural networks. They feature
convolution cells (or pooling layers) and kernels, each serving a
different purpose.

Convolution kernels actually process input data, and pooling layers
simplify it (mostly using non-linear functions, like max), reducing
unnecessary features.

Typically used for image recognition, they operate on small subset of
image (something about 20x20 pixels). The input window is sliding along
the image, pixel by pixel. The data is passed to convolution layers,
that form a funnel (compressing detected features). From the terms of
image recognition, first layer detects gradients, second lines, third
shapes, and so on to the scale of particular objects. DFFs are commonly
attached to the final convolutional layer for further data processing.

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

\textbf{Deep Feed Forward}

(Multilayer Perceptron) \includegraphics{attachment:image.png}

    \hypertarget{regularization}{%
\subsection{REGULARIZATION}\label{regularization}}

The processing of fighting overfitting this way is called
\textbf{regularization}.

A simple model in this context is a model where the distribution of
parameter values has less entropy (or a model with fewer parameters).
Thus a common way to mitigate overfitting is to put constraints on the
complexity of a network by forcing its weights to take only small
values, which makes the distribution of weight values more regular. This
is called weight regularization, and it's done by adding to the loss
function of the network a cost associated with having large weights.
This cost comes in two flavors: * L1 regularization---The cost added is
proportional to the absolute value of the weight coefficients (the L1
norm of the weights). * L2 regularization---The cost added is
proportional to the square of the value of the weight coefficients (the
L2 norm of the weights). L2 regularization is also called weight decay
in the context of neural networks. Don't let the different name con-
fuse you: weight decay is mathematically the same as L2 regularization.

    \hypertarget{adding-l2-weight-regularization-to-the-model}{%
\section{Adding L2 weight regularization to the
model}\label{adding-l2-weight-regularization-to-the-model}}

\texttt{model.add(layers.Dense(16,\ kernel\_regularizer=regularizers.l2(0.001),\ activation=\textquotesingle{}relu\textquotesingle{},\ input\_shape=(10000,)))\ model.add(layers.Dense(16,\ kernel\_regularizer=regularizers.l2(0.001),\ activation=\textquotesingle{}relu\textquotesingle{}))\ model.add(layers.Dense(1,\ activation=\textquotesingle{}sigmoid\textquotesingle{}))}

    l2(0.001) means every coefficient in the weight matrix of the layer will
add 0.001 * weight\_coefficient\_value to the total loss of the network.
Note that because this penalty is only added at training time, the loss
for this network will be much higher at training than at test time.

    \hypertarget{different-weight-regularizers-available-in-keras}{%
\subsection{Different weight regularizers available in
Keras}\label{different-weight-regularizers-available-in-keras}}

\textbf{L1 regularization}

\texttt{from\ keras\ import\ regularizers\ regularizers.l1(0.001)}

\textbf{Simultaneous L1 and L2 regularization}

\texttt{regularizers.l1\_l2(l1=0.001,\ l2=0.001)}

    \hypertarget{dropout}{%
\subsection{DROPOUT}\label{dropout}}

Dropout, applied to a layer, consists of randomly dropping out (setting
to zero) a number of output features of the layer during training. It
was developed by Geoff Hinton and his students at the Uni- versity of
Toronto.

The creator says he was inspired by, among other things, a
fraud-prevention mechanism used by banks. In his own words, ``I went to
my bank. The tellers kept changing and I asked one of them why. He said
he didn't know but they got moved around a lot. I figured it must be
because it would require cooperation between employees to suc- cessfully
defraud the bank. This made me realize that randomly removing a
different subset of neurons on each example \textbf{would prevent
conspiracies} and thus reduce over- fitting. The core idea is that
introducing noise in the output values of a layer can break up
happenstance patterns that aren't significant (what the autho refers to
as con- spiracies), which the network will start memorizing if no noise
is present.

    To recap, these are the most common ways to prevent overfitting in
neural networks: * Get more training data. * Reduce the capacity of the
network. * Add weight regularization. * Add dropout.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
